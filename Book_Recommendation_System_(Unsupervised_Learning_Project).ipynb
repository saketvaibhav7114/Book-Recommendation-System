{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "MSa1f5Uengrz",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saketvaibhav7114/Book-Recommendation-System/blob/main/Book_Recommendation_System_(Unsupervised_Learning_Project).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Book Recommendation System\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Saket Vaibhav"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the last few decades, with the rise of Youtube, Amazon, Netflix, and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\n",
        "\n",
        "A recommendation system helps an organization to create loyal customers and build trust with them by providing the products and services they desire. The recommendation system today is so powerful that it can handle the new customer who has visited the site for the first time. They recommend the products that are currently trending or highly rated, and they can also recommend the products that bring maximum profit to the company.\n",
        "\n",
        "### **Data Collection:**\n",
        "The foundation of any recommendation system is data. In this project, data collection involved gathering information about books, authors, user preferences, and historical reading patterns. The dataset for Book Recommendation System comprises three files:\n",
        "\n",
        "**Users**\n",
        "\n",
        "Contains the users IDs, Location & Age.\n",
        "\n",
        "\n",
        "**Books**\n",
        "\n",
        "Books are identified by their respective ISBN. Some content-based information is also given (Book-Title, Book-Author, Year-Of-Publication, Publisher), obtained from Amazon Web Services.\n",
        "\n",
        "\n",
        "**Ratings**\n",
        "Contains the book rating information expressed on a scale from 1-10 (higher values denoting higher appreciation). The data included details like book titles, genres, authors, user ratings, and textual descriptions.\n",
        "\n",
        "\n",
        "### **Data Preprocessing:**\n",
        "Data preprocessing involved tasks such as cleaning the data, handling missing values, and transforming textual descriptions into numerical representations through techniques like TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "\n",
        "\n",
        "### **Clustering Algorithms:**\n",
        "One of the key components of the recommendation system is the use of clustering algorithms. Unsupervised clustering methods, such as K-Means are applied to group books with similar characteristics. These clusters are created based on factors like genre, author, and book content. The goal is to identify patterns and associations among books that could aid in recommendations.\n",
        "\n",
        "### **Matrix Factorization:**\n",
        "Matrix factorization techniques, including Singular Value Decomposition (SVD) are employed to uncover latent factors that influence user preferences. By decomposing the user-item interaction matrix, these algorithms revealed hidden relationships between users and books. This information is then used to make personalized recommendations.\n",
        "\n",
        "### **Collaborative Filtering:**\n",
        "Collaborative filtering relies on the idea that users who have similar reading preferences will likely enjoy similar books. Collaborative filtering algorithms, such as user-based and item-based collaborative filtering, were implemented to generate recommendations based on user behavior and item similarity. This approach helped in fine-tuning the suggestions.\n",
        "\n",
        "### **Content-Based Filtering:**\n",
        "In addition to collaborative filtering, content-based filtering is used to improve the recommendation system's accuracy. This approach analyzed the textual descriptions of books and matched them with user preferences. Natural Language Processing (NLP) techniques were employed to extract meaningful features from the book descriptions and align them with user profiles.\n",
        "\n",
        "### **Evaluation Metrics:**\n",
        "To assess the performance of the Book Recommendation System, several evaluation metrics are employed. Common metrics included Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and precision-recall metrics. These measures helped gauge the accuracy and effectiveness of the recommendations provided to users."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/saketvaibhav7114/Book-Recommendation-System"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The world of literature is vast, with millions of books spanning various genres and subjects. Navigating this extensive library can be overwhelming for readers looking for their next captivating read. To address this challenge, a Book Recommendation System was developed. This system leverages the power of unsupervised learning algorithms to provide personalized book recommendations to users, enhancing their reading experience."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import sklearn\n",
        "import warnings\n",
        "import random\n",
        "import sklearn\n",
        "import scipy\n",
        "import math\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "# Tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Stemming & Lemmatization\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# ML Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "\n",
        "warnings.simplefilter('ignore')\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ywe4DEDIsDoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Data\n",
        "book_data = pd.read_csv(\"/content/drive/MyDrive/Books.csv\")\n",
        "\n",
        "# Users Data\n",
        "users_data= pd.read_csv('/content/drive/MyDrive/Users.csv')\n",
        "\n",
        "# Ratings Data\n",
        "ratings_data = pd.read_csv(\"/content/drive/MyDrive/Ratings.csv\")\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "# Book Data\n",
        "book_data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Users Data\n",
        "users_data.head()"
      ],
      "metadata": {
        "id": "-R9NWteUtN7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings Data\n",
        "ratings_data.head()"
      ],
      "metadata": {
        "id": "XOSEfBzYxTNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "# Book Data\n",
        "book_data.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.shape"
      ],
      "metadata": {
        "id": "xVQnNiuGxwEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.shape"
      ],
      "metadata": {
        "id": "2ZENFt3nx27W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "# Book Data\n",
        "book_data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.info()"
      ],
      "metadata": {
        "id": "WpD37fA9yEKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.info()"
      ],
      "metadata": {
        "id": "cfAEewfiyGiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# Book Data\n",
        "book_data.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.duplicated().sum()"
      ],
      "metadata": {
        "id": "f6hLUXT-yhYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.duplicated().sum()"
      ],
      "metadata": {
        "id": "Z2v5ekZlyiGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Book Data\n",
        "book_data.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.isnull().sum()"
      ],
      "metadata": {
        "id": "CMCrxl9Dywet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.isnull().sum()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Book Data\n",
        "book_missing_value=book_data.isnull().sum()\n",
        "columns_with_missing_values = book_missing_value[book_missing_value > 0]      #  Filter columns with missing values\n",
        "\n",
        "# Calculate the percentage of missing values in each column\n",
        "total_rows = len(book_data)\n",
        "percentage_missing = (columns_with_missing_values / total_rows) * 100\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bar_plot = columns_with_missing_values.plot(kind='bar', color='lightcoral')\n",
        "plt.xlabel('Columns with Missing Value',fontsize=14)\n",
        "plt.ylabel('Number of Missing Values',fontsize=14)\n",
        "plt.title('Number of Missing Values in Book Dataset',fontsize=14)\n",
        "plt.xticks(rotation=0, ha='center',fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)"
      ],
      "metadata": {
        "id": "_hPLlUovy9t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_missing_value=users_data.isnull().sum()\n",
        "columns_with_missing_values = users_missing_value[users_missing_value > 0]      #  Filter columns with missing values\n",
        "\n",
        "# Calculate the percentage of missing values in each column\n",
        "total_rows = len(book_data)\n",
        "percentage_missing = (columns_with_missing_values / total_rows) * 100\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bar_plot = columns_with_missing_values.plot(kind='bar', color='lightcoral')\n",
        "plt.xlabel('Columns with Missing Value',fontsize=14)\n",
        "plt.ylabel('Number of Missing Values',fontsize=14)\n",
        "plt.title('Number of Missing Values in User Dataset',fontsize=14)\n",
        "plt.xticks(rotation=0, ha='center',fontsize=14)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Display the percentage of missing values on top of bar\n",
        "for index, value in enumerate(columns_with_missing_values):\n",
        "    plt.text(index, value, f'{percentage_missing[index]:.2f}%', ha='center', va='bottom',fontsize=10)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2hK8zancUjcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:**The dataset is well-prepared for further analysis, as it contains no duplicated rows and some missing values which needs to be fixed either by using the fillna method or dropping the rows so that there is a clean and unique dataset for analysis. Most of the missing value is in age columns of users dataset. Most of the features are either objects or floats. If necessary, it needs to be converted into the required datatype. After the necessary cleaning, the dataset will be ready for preprocessing steps, allowing the focus to be on feature engineering and model development to achieve accurate predictions."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "# Book Data\n",
        "book_data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.columns"
      ],
      "metadata": {
        "id": "N-2kGSWcmBkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.columns"
      ],
      "metadata": {
        "id": "0V1GHhBcmLMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Book Data\n",
        "book_data.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.describe().T"
      ],
      "metadata": {
        "id": "MoeKvFnwmk-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.describe().T"
      ],
      "metadata": {
        "id": "3qtPUgpkmqcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "# Book Data\n",
        "book_data.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.nunique()"
      ],
      "metadata": {
        "id": "trGH4Y1PnEZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.nunique()"
      ],
      "metadata": {
        "id": "EqCoDaitnLRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data Cleaning of book dataset"
      ],
      "metadata": {
        "id": "8ZqdCzPVrnBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "book_data.rename(columns = {'Book-Title':'title', 'Book-Author':'author', 'Year-Of-Publication':'year', 'Publisher':'publisher'}, inplace=True)\n",
        "\n",
        "# droping the url\n",
        "book_data.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis= 1, inplace= True)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.info()"
      ],
      "metadata": {
        "id": "bFm-tQAestXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.isnull().sum()"
      ],
      "metadata": {
        "id": "yFGlxbTUsxOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nan values in book_author column\n",
        "book_data.loc[(book_data['author'].isnull()),: ]"
      ],
      "metadata": {
        "id": "WW2saRV3s7Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nan values in publisher column\n",
        "book_data.loc[(book_data['publisher'].isnull()),: ]"
      ],
      "metadata": {
        "id": "uPCdRk0ptG2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting unique value from 'year_of_publication' feature\n",
        "book_data['year'].unique()"
      ],
      "metadata": {
        "id": "UIYwLDSytSih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting rows with year column=\"DK Publishing Inc\"\n",
        "book_data[book_data['year'] == 'DK Publishing Inc']"
      ],
      "metadata": {
        "id": "jYrhiZfptiIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting rows with year column=\"Gallimard\"\n",
        "book_data[book_data['year'] == 'Gallimard']"
      ],
      "metadata": {
        "id": "lj2dXLbT53J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[187689]"
      ],
      "metadata": {
        "id": "-ygOCUGnfsUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[221678]"
      ],
      "metadata": {
        "id": "HM96CO4u_YrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[209538]"
      ],
      "metadata": {
        "id": "Z2R1sY23AUMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[220731]"
      ],
      "metadata": {
        "id": "nvOOp-J1_q21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Let's fix the column and make it in correct format as per our dataset."
      ],
      "metadata": {
        "id": "xkHfkUNjGdVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to fix mismatch data in feature 'book_title', 'book_author', ' year_of_publication', 'publisher'\n",
        "def replace_df_value(df, idx, col_name, val):\n",
        "  df.loc[idx, col_name] = val\n",
        "  return df"
      ],
      "metadata": {
        "id": "Hx6botZkGNL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_df_value(book_data, 209538, 'title', 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)')\n",
        "replace_df_value(book_data, 209538, 'author', 'Michael Teitelbaum')\n",
        "replace_df_value(book_data, 209538, 'year', 2000)\n",
        "replace_df_value(book_data, 209538, 'publisher', 'DK Publishing Inc')\n",
        "\n",
        "replace_df_value(book_data, 221678, 'title', 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)')\n",
        "replace_df_value(book_data, 221678, 'author', 'James Buckley')\n",
        "replace_df_value(book_data, 221678, 'year', 2000)\n",
        "replace_df_value(book_data, 221678, 'publisher', 'DK Publishing Inc')\n",
        "\n",
        "replace_df_value(book_data, 220731,'title', \"Peuple du ciel, suivi de 'Les Bergers\")\n",
        "replace_df_value(book_data, 220731, 'author', 'Jean-Marie Gustave Le ClÃ?Â©zio')\n",
        "replace_df_value(book_data, 220731, 'year', 2003)\n",
        "replace_df_value(book_data, 220731, 'publisher', 'Gallimard')"
      ],
      "metadata": {
        "id": "BTgmCVVfGpvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[209538]"
      ],
      "metadata": {
        "id": "4H6140xzIhIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[221678]"
      ],
      "metadata": {
        "id": "K43aPKgsIkSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[220731]"
      ],
      "metadata": {
        "id": "jY9B6a4XInWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data['year'].unique()"
      ],
      "metadata": {
        "id": "iHNJm90_6RyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the datatype of year column from object to int\n",
        "book_data['year'] = book_data['year'].astype(int)"
      ],
      "metadata": {
        "id": "cDSkFSy86kcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.info()"
      ],
      "metadata": {
        "id": "P8l9MjVt5u-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data Cleaning of user dataset"
      ],
      "metadata": {
        "id": "Nf6OVBZHLiQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renamimg the column\n",
        "users_data.rename(columns = {'User-ID':'user_id', 'Location':'location', 'Age':'age'}, inplace=True)"
      ],
      "metadata": {
        "id": "EW2Ix73_SjZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_data.info()"
      ],
      "metadata": {
        "id": "HQLso6xAS7ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data Cleaning of ratings dataset"
      ],
      "metadata": {
        "id": "zQ_HdOruXy2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renamimg the column\n",
        "ratings_data.rename(columns = {'User-ID':'user_id', 'Book-Rating':'rating'}, inplace=True)"
      ],
      "metadata": {
        "id": "SYfhmrMEXySO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data.info()"
      ],
      "metadata": {
        "id": "MKyq2-GjYHUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data['rating'].unique()"
      ],
      "metadata": {
        "id": "HSewyYltYXgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data['user_id'].value_counts()"
      ],
      "metadata": {
        "id": "9h3--EmrY1-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A big flaw with a problem statement in the rating dataset**\n",
        "\n",
        "If we take all the books and all the users for modeling, it will create a problem because we cannot consider a user who has only registered on the website or has only read one or two books. On such a user, we cannot rely to recommend books to others because we have to extract knowledge from data. So we will limit this number and we will take a user who has rated at least 200 books and also we will limit books and we will take only those books which have received at least 50 ratings from a user."
      ],
      "metadata": {
        "id": "lwMP-SmqgQKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract users who has rated more than 200 books**"
      ],
      "metadata": {
        "id": "4zeVrI3Pg4Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = ratings_data['user_id'].value_counts() > 200"
      ],
      "metadata": {
        "id": "A9Avzed_gPJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = x[x].index  # user_ids\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "vNbuDmUNiSQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data = ratings_data[ratings_data['user_id'].isin(y)]"
      ],
      "metadata": {
        "id": "BIeMrXM3hMSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data.shape"
      ],
      "metadata": {
        "id": "HvrZ_KrciI7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So 900 users are there who have given 5.2 lakh rating"
      ],
      "metadata": {
        "id": "vmR3oyd-zIKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Average Ratings of Each Book"
      ],
      "metadata": {
        "id": "YHZjs1omw48e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_rating = ratings_data.groupby('ISBN').count()['rating'].reset_index()\n",
        "number_rating.rename(columns= {'rating':'number_of_ratings'}, inplace=True)\n",
        "number_rating"
      ],
      "metadata": {
        "id": "WBU6eLnh1ohs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_rating=ratings_data.merge(number_rating,on='ISBN')\n",
        "final_rating"
      ],
      "metadata": {
        "id": "c9AGy6lDtiOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract books that have received more than 50 ratings."
      ],
      "metadata": {
        "id": "1QZ-JGaXzwOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_rating = final_rating[final_rating['number_of_ratings'] >= 50]"
      ],
      "metadata": {
        "id": "GegSY_G31yes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Duplicated Row\n",
        "final_rating.drop_duplicates(['user_id','ISBN'], inplace=True)"
      ],
      "metadata": {
        "id": "PHqVPUNw4A_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merge ratings with books_data & user_data**\n",
        "\n",
        "> Merge ratings with books on basis of ISBN so that we will get the rating of each user on each book id and the user who has not rated that book id the value will be zero.\n",
        "\n",
        "> Merge ratings_with_books on basis of user_id so that we will get the rating of each user on each book id and the user who has not rated that book id the value will be zero\n",
        "\n"
      ],
      "metadata": {
        "id": "uxf-PpZQvDJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_with_books = final_rating.merge(book_data, on='ISBN')"
      ],
      "metadata": {
        "id": "lF2ItEn7vQ8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Merge Final Rating Dataset with the Users Dataset**"
      ],
      "metadata": {
        "id": "i3YVSzPNGMOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users=rating_with_books.merge(users_data,on='user_id')"
      ],
      "metadata": {
        "id": "J0Ce7yIeCW1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.head()"
      ],
      "metadata": {
        "id": "8FT1vKU_G-78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract 'country' values from 'location' column\n",
        "rating_book_users['country'] = rating_book_users['location'].str.split(',').str[-1].str.strip()\n",
        "\n",
        "# Drop the 'location' column\n",
        "rating_book_users.drop(columns=['location'], inplace=True)"
      ],
      "metadata": {
        "id": "-h_sXIAgF_6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users['country'].unique()"
      ],
      "metadata": {
        "id": "i-rwQI5lrHbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'usa' with 'us',double quotes (\") & 'n/a' with 'nan' in 'country' column\n",
        "rating_book_users['country'] = rating_book_users['country'].str.replace('usa','us').replace('n/a',np.nan).replace('', np.nan)\n",
        "\n",
        "# Display the modified 'country' column\n",
        "rating_book_users['country'].unique()"
      ],
      "metadata": {
        "id": "5diOKOVGrNcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.tail()"
      ],
      "metadata": {
        "id": "vodb_3xIC5Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.shape"
      ],
      "metadata": {
        "id": "8lZ98F60H7in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we have a dataset with that user who has rated more than 200 books and books that received more than 50 ratings. The shape of the final dataframe is 59850 rows and 10 columns."
      ],
      "metadata": {
        "id": "xeqgSEcU-UKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.info()"
      ],
      "metadata": {
        "id": "zseQ5Bo6CYyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.loc[41803]"
      ],
      "metadata": {
        "id": "rwCUAOW5DTB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(14,6))\n",
        "ax=sns.countplot(x=\"rating\",palette = 'Paired',data= rating_book_users)\n",
        "plt.title('Count of Each Ratings',fontsize=15)\n",
        "plt.xlabel('Rating',fontsize=15)\n",
        "plt.ylabel('Count',fontsize=15)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "# Add value annotations to the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'),\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.distplot(rating_book_users['age'])\n",
        "plt.title('Age Distribution\\n',fontsize=15)\n",
        "plt.xlabel('Age',fontsize=15)\n",
        "plt.ylabel('Count',fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UdEpXJaeu-DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "sns.boxplot(rating_book_users['age'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X1MsfPczvU2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "sns.boxplot(rating_book_users['year'])"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "sns.boxplot(rating_book_users['number_of_ratings'])"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "sns.boxplot(rating_book_users['rating'])"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(15,6))\n",
        "ax=sns.countplot(data=rating_book_users, y=\"author\", palette = 'Paired', order=rating_book_users['author'].value_counts().index[0:20])\n",
        "plt.title(\"Top 20 author with number of books\",fontsize=15)\n",
        "plt.xlabel(\"Count of Books\",fontsize=15)\n",
        "plt.ylabel(\"Author Name\",fontsize=15)\n",
        "\n",
        "# Add values on top of each bar\n",
        "for p in ax.patches:\n",
        "    width = p.get_width()\n",
        "    plt.text(width + 40, p.get_y() + p.get_height() / 2, f'{int(width)}',\n",
        "             ha='center', va='center', fontsize=10, color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(15, 6))\n",
        "ax = sns.countplot(data=rating_book_users, y=\"publisher\", palette='Paired',\n",
        "                   order=rating_book_users['publisher'].value_counts().index[0:20])\n",
        "\n",
        "# Set the title\n",
        "plt.title(\"Top 20 Publishers with the number of books published\", fontsize=15)\n",
        "plt.xlabel(\"Number of Books\", fontsize=15)\n",
        "plt.ylabel(\"Publishers Name\", fontsize=15)\n",
        "\n",
        "# Adding values of each bar\n",
        "for p in ax.patches:\n",
        "    width = p.get_width()\n",
        "    plt.text(width + 80, p.get_y() + p.get_height() / 2, f'{int(width)}',\n",
        "             ha='center', va='center', fontsize=10, color='black')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create a countplot for the top 15 books based on the number of ratings\n",
        "ax = sns.countplot(y=\"title\", palette='Paired', data=rating_book_users, order=rating_book_users['title'].value_counts().index[0:15])\n",
        "plt.title(\"Top 15 Books by Number of Ratings\", fontsize=15)\n",
        "plt.xlabel(\"Total Number of Ratings Given\", fontsize=15)\n",
        "plt.ylabel(\"Book Title\", fontsize=15)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=8)\n",
        "\n",
        "# Adding values on top of each bar\n",
        "for p in ax.patches:\n",
        "    width = p.get_width()\n",
        "    plt.text(width + 7, p.get_y() + p.get_height() / 2, f'{int(width)}',\n",
        "             ha='center', va='center', fontsize=10, color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c9lDuasX28e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Create a countplot for the number of books published each year\n",
        "ax=sns.countplot(data=rating_book_users, x=\"year\", palette='Paired', order=sorted(rating_book_users['year'].unique()))\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title(\"Number of Books Published Each Year\")\n",
        "plt.xlabel(\"Year\",fontsize=15)\n",
        "plt.ylabel(\"Number of Books\",fontsize=15)\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Add values on top of each bar\n",
        "for p in ax.patches:\n",
        "  ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2, p.get_height()+30),\n",
        "                ha='center', va='bottom', fontsize=10, color='black')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dx5vEbsp5Xtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Filter out rows where 'year' is not equal to 0\n",
        "filtered_final_data = rating_book_users[rating_book_users['year'] != 0]\n",
        "\n",
        "sns.lineplot(x='year', y='number_of_ratings', data=filtered_final_data)\n",
        "\n",
        "plt.title(\"Number of Ratings Over the Years\", fontsize=15)\n",
        "plt.xlabel(\"Year\", fontsize=15)\n",
        "plt.ylabel(\"Number of Ratings\", fontsize=15)\n",
        "\n",
        "plt.xticks(range(min(filtered_final_data['year']), max(filtered_final_data['year'])+1, 5))\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Group the data by 'country' and count the unique 'author' values in each group\n",
        "country_author_counts = rating_book_users.groupby('country')['author'].nunique()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(14, 7))\n",
        "ax=country_author_counts.plot(kind='bar',color='skyblue')\n",
        "plt.title('Number of Unique Authors by Country',fontsize=15)\n",
        "plt.xlabel('Country',fontsize=15)\n",
        "plt.ylabel('Number of Unique Authors',fontsize=15)\n",
        "plt.xticks(rotation=90,fontsize=11)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Add value annotations to the bars\n",
        "for i, v in enumerate(country_author_counts):\n",
        "  ax.text(i, v + 1, str(v), ha='center', va='bottom', fontsize=11)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "\n",
        "# Group the data by 'country' and count the unique 'publisher' values in each group\n",
        "country_publisher_counts = rating_book_users.groupby('country')['publisher'].nunique()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(14, 7))\n",
        "ax = country_publisher_counts.plot(kind='bar', color='skyblue')\n",
        "plt.title('Number of Unique Publishers by Country', fontsize=15)\n",
        "plt.xlabel('Country', fontsize=15)\n",
        "plt.ylabel('Number of Unique Publishers', fontsize=15)\n",
        "plt.xticks(rotation=90,fontsize=11)\n",
        "\n",
        "# Add value annotations to the bars\n",
        "for i, v in enumerate(country_publisher_counts):\n",
        "    ax.text(i, v + 0.1, str(v), ha='center', va='bottom', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = rating_book_users.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Heatmap of rating_book_users\", fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(rating_book_users)"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothetical Statement 1:** The average age of users from the United States ('USA') is higher than the average age of users from Canada ('Canada').\n",
        "\n",
        "**Hypothetical Statement 2:** The average age of users who rated books with a rating of 5 is higher than the average age of users who rated books with a rating less than 5.\n",
        "\n",
        "**Hypothetical Statement 3:** The average number of ratings for books with a rating of 5 is significantly higher than the average number of ratings for books with a rating less than 5."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** The average age of users from the USA is equal to the average age of users from Canada.\n",
        "\n",
        "**Alternative Hypothesis (H1):** The average age of users from the USA is not equal to the average age of users from Canada."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Separate the data for users from the USA and Canada\n",
        "age_usa = rating_book_users[rating_book_users['country'] == 'us']['age'].dropna()\n",
        "age_canada = rating_book_users[rating_book_users['country'] == 'canada']['age'].dropna()\n",
        "\n",
        "# Perform a t-test\n",
        "t_statistic, p_value = stats.ttest_ind(age_usa, age_canada, alternative='two-sided')\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print results\n",
        "print(\"t-statistic:\", t_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "if p_value < alpha:\n",
        "  print(\"Reject the null hypothesis: The average age of users from the USA is not equal to the average age of users from Canada.\")\n",
        "else:\n",
        "  print(\"Fail to reject the null hypothesis: The average age of users from the USA is equal to the average age of users from Canada.\")"
      ],
      "metadata": {
        "id": "BxjxG2ZxaAPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test are performed to find P-value"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test is commonly used to compare the means of two samples or groups to assess whether the observed difference is statistically significant or if it could have occurred by chance."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** The average age of users who rated books with a rating of 5 is equal to the average age of users who rated books with a rating less than 5.\n",
        "\n",
        "**Alternative Hypothesis (H1):** The average age of users who rated books with a rating of 5 is not equal to the average age of users who rated books with a rating less than 5."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Separate the data for users who rated books with a rating of 5 and users who rated books with a rating less than 5\n",
        "age_rating_5 = rating_book_users[rating_book_users['rating'] == 5]['age'].dropna()\n",
        "age_rating_less_than_5 = rating_book_users[rating_book_users['rating'] < 5]['age'].dropna()\n",
        "\n",
        "# Perform a one-tailed t-test (greater)\n",
        "t_stat, p_value = stats.ttest_ind(age_rating_5, age_rating_less_than_5, alternative='two-sided')\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print results\n",
        "print(\"t-statistic:\", t_stat)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "if p_value < alpha:\n",
        "  print(\"Reject the null hypothesis: The average age of users who rated books with a rating of 5 is not equal\\\n",
        "        \\nto average age of users who rated books with a rating less than 5.\")\n",
        "\n",
        "else:\n",
        "  print(\"Fail to reject the null hypothesis: The average age of users who rated books with a rating of 5 is equal\\\n",
        "        \\nto the average age of users who rated books with a rating less than 5.\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test are performed to find P-value"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test is commonly used to compare the means of two samples or groups to assess whether the observed difference is statistically significant or if it could have occurred by chance."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** The average number of ratings for books with a rating of 5 is equal to the average number of ratings for books with a rating less than 5.\n",
        "\n",
        "**Alternative Hypothesis (H1):** The average number of ratings for books with a rating of 5 is higher than the average number of ratings for books with a rating less than 5."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Separate the data for books with a rating of 5 and books with a rating less than 5\n",
        "num_ratings_rating_5 = rating_book_users[rating_book_users['rating'] == 5]['number_of_ratings']\n",
        "num_ratings_rating_less_than_5 = rating_book_users[rating_book_users['rating'] < 5]['number_of_ratings']\n",
        "\n",
        "# Perform a one-tailed t-test (greater)\n",
        "t_stat, p_value = stats.ttest_ind(num_ratings_rating_5, num_ratings_rating_less_than_5, alternative='greater')\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print results\n",
        "print(\"t-statistic:\", t_stat)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The average number of ratings for books with a rating of 5\\\n",
        "          \\nis higher than the average number of ratings for books with a rating less than 5.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The average number of ratings for books with a rating of 5\\\n",
        "            \\nis equal to the average number of ratings for books with a rating less than 5.\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test are performed to find P-value"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test is commonly used to compare the means of two samples or groups to assess whether the observed difference is statistically significant or if it could have occurred by chance."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making copy of original dataframe\n",
        "df=final_rating.copy()"
      ],
      "metadata": {
        "id": "JG6G_ZefAELm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "fgBvpgYczSTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "YgqVYNRhe75R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "sPq-Gh3efNN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.isnull().sum()"
      ],
      "metadata": {
        "id": "qEa8d-rYgeyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode_publisher = book_data['publisher'].mode()[0]\n",
        "mode_author = book_data['author'].mode()[0]\n",
        "\n",
        "# Fill missing values in 'publisher' and 'author' columns with their respective modes\n",
        "book_data['publisher'].fillna(mode_publisher, inplace=True)\n",
        "book_data['author'].fillna(mode_author, inplace=True)"
      ],
      "metadata": {
        "id": "LShjnKvmgmYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.isnull().sum()"
      ],
      "metadata": {
        "id": "lAJcFHwghiAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** There is no missing value in the dataset. Hence no need to impute any missing value."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "sns.boxplot(df)"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** There is no outlier in the dataset."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "avg_rating=df.groupby('ISBN').mean()['rating'].reset_index()\n",
        "avg_rating.rename(columns= {'rating':'avg_ratings'}, inplace=True)\n",
        "avg_rating.head()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging avg_rating dataset with original df dataset on 'ISBN'"
      ],
      "metadata": {
        "id": "AFkkxKKJQ3dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_rating_df=df.merge(avg_rating,on='ISBN')\n",
        "avg_rating_df.head()"
      ],
      "metadata": {
        "id": "2qrJulY6QeXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=book_data.copy()"
      ],
      "metadata": {
        "id": "fg0dSclgV5UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "fY0v4SHl6vKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "def string_lower(word):\n",
        "  return word.lower()\n",
        "df['title']=df['title'].apply(string_lower)\n",
        "df['author']=df['author'].apply(string_lower)\n",
        "df['publisher']=df['publisher'].apply(string_lower)"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "gS1012jx_ZR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "[punc for punc in string.punctuation]"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(text):\n",
        "  nopunc =[char for char in text if char not in string.punctuation]\n",
        "  nopunc=''.join(nopunc)\n",
        "  return nopunc\n",
        "df['title']=df['title'].apply(remove_punc)\n",
        "df['author']=df['author'].apply(remove_punc)\n",
        "df['publisher']=df['publisher'].apply(remove_punc)"
      ],
      "metadata": {
        "id": "ZjN0Xzp4AVO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "\n",
        "# Function to remove digits from text & sentence\n",
        "def remove_digits(text):\n",
        "  return ''.join([char for char in text if not char.isdigit()])\n",
        "\n",
        "# Apply the remove_digits function to the 'text' column\n",
        "df['title']=df['title'].apply(remove_digits)\n",
        "df['author']=df['author'].apply(remove_digits)\n",
        "df['publisher']=df['publisher'].apply(remove_digits)"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopword\n",
        "\n",
        "def remove_stopwords(sentence, language='english'):\n",
        "  # Get the list of stopwords for the specified language\n",
        "  stop_words = set(stopwords.words(language))\n",
        "  words = sentence.split()\n",
        "\n",
        "  # Remove stopwords from the list of words\n",
        "  filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "  # Join the filtered words to form a sentence without stopwords\n",
        "  filtered_sentence = ' '.join(filtered_words)\n",
        "  return filtered_sentence"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title']=df['title'].apply(remove_stopwords)\n",
        "df['author']=df['author'].apply(remove_stopwords)\n",
        "df['publisher']=df['publisher'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "5XvjdKopIJx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "df['title']=df['title'].replace(\" \",\"\")\n",
        "df['author']=df['author'].replace(\" \",\"\")\n",
        "df['publisher']=df['publisher'].replace(\" \",\"\")"
      ],
      "metadata": {
        "id": "YBOa7XenZxcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "# Create a new columns & Concatenate all the columns into it\n",
        "df['tags']=df['title']+df['author']+df['publisher']\n",
        "df.head()"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the 'tags' column using nltk\n",
        "df['tokenized_tags'] = df['tags'].apply(word_tokenize)\n",
        "\n",
        "# Display the result\n",
        "df"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new dataframe\n",
        "book_data_new=df[['ISBN','tokenized_tags']]\n",
        "book_data_new"
      ],
      "metadata": {
        "id": "f0MVqSGhq4Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "\n",
        "# Create lemmatizer objects\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "\n",
        "# Define a function to lemmatize and join tokens\n",
        "def lemmatize_and_join(tokens):\n",
        "  # Lemmatize each token and join them back into a single string\n",
        "  lemmatized_text = \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
        "\n",
        "  return lemmatized_text\n",
        "\n",
        "book_data_new['tokenized_tags']=book_data_new['tokenized_tags'].apply(lemmatize_and_join)\n",
        "book_data_new.head()\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Lemmatiztaion technique is used for text normalization because Lemmatization produces more linguistically correct and readable words compared to stemming."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "stopwords_list = stopwords.words('french') + stopwords.words('portuguese') + stopwords.words('spanish') + stopwords.words('german')+ stopwords.words('finnish')+ stopwords.words('swedish')\n",
        "\n",
        "#Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
        "vectorizer = TfidfVectorizer(analyzer='word',\n",
        "                     ngram_range=(1, 2),\n",
        "                     min_df=0.03,\n",
        "                     max_df=0.6,\n",
        "                     max_features=5000,\n",
        "                     stop_words=stopwords_list)\n",
        "tfidf_matrix = vectorizer.fit_transform(book_data_new['tokenized_tags']).toarray()\n",
        "tfidf_matrix"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "r-NW_DIwzIbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix.shape"
      ],
      "metadata": {
        "id": "pMnNqUN-29KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(avg_rating_df, test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training set lengths: {len(train_data)}')\n",
        "print(f'Testing set lengths: {len(test_data)}')\n",
        "print(f'Test set is {(len(test_data)/(len(train_data)+len(test_data))*100):.0f}% of the full dataset.')"
      ],
      "metadata": {
        "id": "6uRNtEF-5Cm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Splitting ratio is set to 20 % because it is a usual practice keep 80 % of data for training purpose & 20% data for testing purpose."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Indexing by user_id to speed up the searches during evaluation\n",
        "interactions_full_indexed_df = avg_rating_df.set_index('user_id')\n",
        "interactions_train_indexed_df =train_data.set_index('user_id')\n",
        "interactions_test_indexed_df = test_data.set_index('user_id')"
      ],
      "metadata": {
        "id": "0Nvc3qTzV3zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "2CBNyZCJ5-xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1-Collaborative Filtering Method"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a sparse pivot table with ISBN in rows and user_id in columns\n",
        "users_items_pivot_matrix_df = train_data.pivot_table(columns='ISBN', index='user_id', values=\"avg_ratings\")"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix_df.shape"
      ],
      "metadata": {
        "id": "M3qDN2gcpioj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix_df.head()"
      ],
      "metadata": {
        "id": "JSykv0jjpx6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix_df.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "L1YYwlW_pxv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix_df.head()"
      ],
      "metadata": {
        "id": "wzyaLJIpqVDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix=users_items_pivot_matrix_df.values\n",
        "users_items_pivot_matrix[:10]"
      ],
      "metadata": {
        "id": "L2ss_MnyVKVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = list(users_items_pivot_matrix_df.index)\n",
        "user_id[:10]"
      ],
      "metadata": {
        "id": "TVgYqoBXVN4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of factors to factor the user-item matrix.\n",
        "NUMBER_OF_FACTORS_MF = 15\n",
        "\n",
        "#Performs matrix factorization of the original user item matrix\n",
        "U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)"
      ],
      "metadata": {
        "id": "RiOIArE7VpTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix.shape"
      ],
      "metadata": {
        "id": "QWe8zFTFVtJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U.shape"
      ],
      "metadata": {
        "id": "yMCSuRr4Vw6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = np.diag(sigma)\n",
        "sigma.shape"
      ],
      "metadata": {
        "id": "7wU5YNelVz0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vt.shape"
      ],
      "metadata": {
        "id": "mHdZTCGiV5aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "all_user_predicted_ratings"
      ],
      "metadata": {
        "id": "YtjuQZrjV8iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_user_predicted_ratings.shape"
      ],
      "metadata": {
        "id": "0dQRFCJ6WFSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the reconstructed matrix back to a Pandas dataframe\n",
        "cf_preds_df = pd.DataFrame(all_user_predicted_ratings, columns = users_items_pivot_matrix_df.columns, index=user_id).transpose()\n",
        "cf_preds_df.head()"
      ],
      "metadata": {
        "id": "QEM_shH6qcTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cf_preds_df.columns)"
      ],
      "metadata": {
        "id": "bXHhLEtYWXMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFRecommender:\n",
        "\n",
        "    MODEL_NAME = 'Collaborative Filtering'\n",
        "\n",
        "    def __init__(self, cf_predictions_df, items_df=None):\n",
        "        self.cf_predictions_df = cf_predictions_df\n",
        "        self.items_df = items_df\n",
        "\n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        # Get and sort the user's predictions\n",
        "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False).reset_index().rename(columns={user_id: 'recStrength'})\n",
        "\n",
        "        # Recommend the highest predicted rating content that the user hasn't seen yet.\n",
        "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['ISBN'].isin(items_to_ignore)].sort_values('recStrength', ascending = False).head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left',\n",
        "                                                          left_on = 'ISBN',\n",
        "                                                          right_on = 'ISBN')[['recStrength', 'ISBN','title']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "\n",
        "cf_recommender_model = CFRecommender(cf_preds_df,book_data)"
      ],
      "metadata": {
        "id": "xu9Mu6N7Wbe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Top-N accuracy metric choosen was Recall@N which evaluates whether the interacted item is among the top N items (hit) in the ranked list of 101 recommendations for a user."
      ],
      "metadata": {
        "id": "GVRa5Z-6XIRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_items_interacted(user_id, ratings_data):\n",
        "    interacted_items = ratings_data.loc[user_id]['ISBN']\n",
        "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
      ],
      "metadata": {
        "id": "fXE-M_PRXMVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top-N accuracy metrics consts\n",
        "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
        "\n",
        "class ModelEvaluator:\n",
        "\n",
        "    # Function for getting the set of items which a user has not interacted with\n",
        "    def get_not_interacted_items_sample(self, user_id, sample_size, seed=42):\n",
        "        interacted_items = get_items_interacted(user_id, interactions_full_indexed_df)\n",
        "        all_items = set(book_data['ISBN'])\n",
        "        non_interacted_items = all_items - interacted_items\n",
        "\n",
        "        random.seed(seed)\n",
        "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "        return set(non_interacted_items_sample)\n",
        "\n",
        "    # Function to verify whether a particular item_id was present in the set of top N recommended items\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
        "            try:\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "            except:\n",
        "                index = -1\n",
        "            hit = int(index in range(0, topn))\n",
        "            return hit, index\n",
        "\n",
        "    # Function to evaluate the performance of model for each user\n",
        "    def evaluate_model_for_user(self, model, user_id):\n",
        "      try:\n",
        "\n",
        "        # Getting the items in test set\n",
        "        interacted_values_testset = interactions_test_indexed_df.loc[user_id]\n",
        "\n",
        "        if type(interacted_values_testset['ISBN']) == pd.Series:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "        else:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
        "\n",
        "        # Getting a ranked recommendation list from the model for a given user\n",
        "        person_recs_df = model.recommend_items(user_id, items_to_ignore=get_items_interacted(user_id, interactions_train_indexed_df),topn=10000000000)\n",
        "\n",
        "        hits_at_5_count = 0\n",
        "        hits_at_10_count = 0\n",
        "\n",
        "        # For each item the user has interacted in test set\n",
        "        for item_id in person_interacted_items_testset:\n",
        "\n",
        "            # Getting a random sample of 100 items the user has not interacted with\n",
        "            non_interacted_items_sample = self.get_not_interacted_items_sample(user_id, sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS)\n",
        "\n",
        "            # Combining the current interacted item with the 100 random items\n",
        "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
        "\n",
        "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
        "            valid_recs_df = person_recs_df[person_recs_df['ISBN'].isin(items_to_filter_recs)]\n",
        "            valid_recs = valid_recs_df['ISBN'].values\n",
        "\n",
        "            # Verifying if the current interacted item is among the Top-N recommended items\n",
        "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
        "            hits_at_5_count += hit_at_5\n",
        "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
        "            hits_at_10_count += hit_at_10\n",
        "\n",
        "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items\n",
        "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
        "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
        "\n",
        "        user_metrics = {'hits@5_count':hits_at_5_count,\n",
        "                          'hits@10_count':hits_at_10_count,\n",
        "                          'interacted_count': interacted_items_count_testset,\n",
        "                          'recall@5': recall_at_5,\n",
        "                          'recall@10': recall_at_10}\n",
        "        return user_metrics\n",
        "      except KeyError:\n",
        "        # Handle the KeyError gracefully, e.g., by returning default metrics or logging the error\n",
        "        print(f\"User with user_id {user_id} not found in the test set.\")\n",
        "        return {'hits@5_count': 0, 'hits@10_count': 0, 'interacted_count': 0, 'recall@5': 0, 'recall@10': 0}\n",
        "\n",
        "\n",
        "    # Function to evaluate the performance of model at overall level\n",
        "    def evaluate_model(self, model):\n",
        "\n",
        "        people_metrics = []\n",
        "\n",
        "        for idx, user_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
        "            person_metrics = self.evaluate_model_for_user(model, user_id)\n",
        "            person_metrics['_user_id'] = user_id\n",
        "            people_metrics.append(person_metrics)\n",
        "\n",
        "        print('{0} users processed' .format(idx))\n",
        "\n",
        "        detailed_results_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
        "\n",
        "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "\n",
        "        global_metrics = {'modelName': model.get_model_name(),\n",
        "                          'recall@5': global_recall_at_5,\n",
        "                          'recall@10': global_recall_at_10}\n",
        "        return global_metrics, detailed_results_df\n",
        "\n",
        "model_evaluator = ModelEvaluator()"
      ],
      "metadata": {
        "id": "8_hMVrr5XTkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
        "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\n",
        "\n",
        "# Move the user_id column to the first position\n",
        "user_id_column = cf_detailed_results_df['_user_id']  # Extract the user_id column\n",
        "cf_detailed_results_df = cf_detailed_results_df.drop(columns=['_user_id'])\n",
        "cf_detailed_results_df.insert(0, '_user_id', user_id_column)\n",
        "\n",
        "print('\\nGlobal metrics:\\n{}'.format(cf_global_metrics))\n",
        "cf_detailed_results_df.head(10)"
      ],
      "metadata": {
        "id": "gdcO5MtsXaxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 Content Based Filtering"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain vector embeddings of each word in our corpus using TF-IDF Vectorizer technique."
      ],
      "metadata": {
        "id": "XOSiZBf1WH_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "ms5gnqVR41oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Ignoring stopwords (words with no semantics) from English\n",
        "from langdetect import detect\n",
        "stopwords_list = stopwords.words('english')\n",
        "\n",
        "#Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
        "vectorizer = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0.003,max_df=0.5,max_features=5000,stop_words=stopwords_list)\n",
        "\n",
        "item_ids = book_data['ISBN'].tolist()\n",
        "tfidf_matrix = vectorizer.fit_transform(book_data['title'] + \"\" + book_data['author'] + \"\" + book_data['publisher'])\n",
        "tfidf_feature_names = vectorizer.get_feature_names_out()\n"
      ],
      "metadata": {
        "id": "WYmjD14uWHdm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix.shape"
      ],
      "metadata": {
        "id": "HZZuZtn4sIo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# stopwords_list"
      ],
      "metadata": {
        "id": "RbBdh1zOVcc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tfidf_feature_names"
      ],
      "metadata": {
        "id": "PwCsaEI_VcR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To model the user profile, we take all the item profiles the user has interacted and average them. The average is weighted by the interaction strength, in other words, the articles the user has interacted the most (eg. liked or commented) will have a higher strength in the final user profile."
      ],
      "metadata": {
        "id": "MikoRXvLm96n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_item_profile(item_id):\n",
        "  try:\n",
        "    idx = item_ids.index(item_id)\n",
        "    item_profile = tfidf_matrix[idx:idx+1]\n",
        "    return item_profile\n",
        "\n",
        "  except ValueError:\n",
        "    # Handle the case where the item_id is not found\n",
        "    print(f\"Item with ISBN '{item_id}' not found in the list.\")\n",
        "    return None\n",
        "\n",
        "def get_item_profiles(ids):\n",
        "  item_profiles_list = [get_item_profile(x) for x in ids]\n",
        "  item_profiles = scipy.sparse.vstack(item_profiles_list)\n",
        "  return item_profiles\n",
        "\n",
        "\n",
        "def build_users_profile(user_id, avg_indexed_df):\n",
        "  interactions_person_df = avg_indexed_df.loc[user_id]\n",
        "  user_item_profiles = get_item_profiles(interactions_person_df['ISBN'])\n",
        "  user_item_strengths = np.array(interactions_person_df['avg_ratings']).reshape(-1, 1)\n",
        "  return user_item_strengths\n",
        "\n",
        "\n",
        "def build_users_profiles():\n",
        "  avg_indexed_df = avg_rating_df[avg_rating_df['ISBN'].isin(book_data['ISBN'])].set_index('user_id')\n",
        "  user_profiles = {}\n",
        "  for user_id in avg_indexed_df.index.unique():\n",
        "      user_profiles[user_id] = build_users_profile(user_id, avg_indexed_df)\n",
        "  return user_profiles\n"
      ],
      "metadata": {
        "id": "Pf-QOoyw0BIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_profiles = build_users_profiles()\n",
        "len(user_profiles)"
      ],
      "metadata": {
        "id": "KyX7KY69ozus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_profiles"
      ],
      "metadata": {
        "id": "1NzBzkXshB8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at a particular user profile. It is a unit vector of 5000 length. The value in each position represents how relevant is a token (unigram or bigram) for the selected user"
      ],
      "metadata": {
        "id": "529Lpco1iQFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_profile = user_profiles[222488]\n",
        "print(user_profile.shape)\n",
        "\n",
        "pd.DataFrame(sorted(zip(tfidf_feature_names,\n",
        "                        user_profiles[222488].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
        "             columns=['token', 'relevance'])"
      ],
      "metadata": {
        "id": "CYZZpGoQiTo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class for Content-Based Filtering"
      ],
      "metadata": {
        "id": "eUEnXpFoi24l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContentBasedRecommender:\n",
        "\n",
        "    MODEL_NAME = 'Content-Based'\n",
        "\n",
        "    def __init__(self, items_df=None):\n",
        "        self.item_ids = item_ids\n",
        "        self.items_df = items_df\n",
        "\n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "\n",
        "    def _get_similar_items_to_user_profile(self, user_id, topn=1000):\n",
        "\n",
        "        # Compute the cosine similarity between the user profile and all item profiles\n",
        "        cosine_similarities = cosine_similarity(user_profiles[user_id], tfidf_matrix)\n",
        "\n",
        "        # Get the top similar items\n",
        "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
        "\n",
        "        # Sort the similar items by similarity\n",
        "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
        "        return similar_items\n",
        "\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        similar_items = self._get_similar_items_to_user_profile(user_id)\n",
        "\n",
        "        #Ignores items the user has already interacted\n",
        "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
        "\n",
        "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['ISBN', 'recStrength']).head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left',\n",
        "                                                          left_on = 'ISBN',\n",
        "                                                          right_on = 'ISBN')[['recStrength', 'ISBN','title']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "\n",
        "content_based_recommender_model = ContentBasedRecommender(book_data)"
      ],
      "metadata": {
        "id": "Zpr32V49jCoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "hSL-8qRmjvUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Top-N accuracy metrics consts\n",
        "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
        "\n",
        "class ModelEvaluator:\n",
        "\n",
        "    # Function for getting the set of items which a user has not interacted with\n",
        "    def get_not_interacted_items_sample(self, user_id, sample_size, seed=42):\n",
        "      interacted_items = get_items_interacted(user_id, interactions_full_indexed_df)\n",
        "      all_items = set(book_data['ISBN'])\n",
        "      non_interacted_items = all_items - interacted_items\n",
        "\n",
        "      random.seed(seed)\n",
        "      non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "      return set(non_interacted_items_sample)\n",
        "\n",
        "    # Function to verify whether a particular item_id was present in the set of top N recommended items\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
        "      try:\n",
        "        index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "      except:\n",
        "        index = -1\n",
        "      hit = int(index in range(0, topn))\n",
        "      return hit, index\n",
        "\n",
        "\n",
        "    # Function to evaluate the performance of model for each user\n",
        "    def evaluate_model_for_user(self, model, user_id):\n",
        "      try:\n",
        "\n",
        "        # Getting the items in test set\n",
        "        interacted_values_testset = interactions_test_indexed_df.loc[user_id]\n",
        "\n",
        "        if type(interacted_values_testset['ISBN']) == pd.Series:\n",
        "          person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "        else:\n",
        "          person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
        "\n",
        "        # Getting a ranked recommendation list from the model for a given user\n",
        "        person_recs_df = model.recommend_items(user_id, items_to_ignore=get_items_interacted(user_id, interactions_train_indexed_df),topn=10000000000)\n",
        "\n",
        "        hits_at_5_count = 0\n",
        "        hits_at_10_count = 0\n",
        "\n",
        "        # For each item the user has interacted in test set\n",
        "        for item_id in person_interacted_items_testset:\n",
        "\n",
        "            # Getting a random sample of 100 items the user has not interacted with\n",
        "            non_interacted_items_sample = self.get_not_interacted_items_sample(user_id, sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS)\n",
        "\n",
        "            # Combining the current interacted item with the 100 random items\n",
        "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
        "\n",
        "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
        "            valid_recs_df = person_recs_df[person_recs_df['ISBN'].isin(items_to_filter_recs)]\n",
        "            valid_recs = valid_recs_df['ISBN'].values\n",
        "\n",
        "            # Verifying if the current interacted item is among the Top-N recommended items\n",
        "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
        "            hits_at_5_count += hit_at_5\n",
        "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
        "            hits_at_10_count += hit_at_10\n",
        "\n",
        "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items\n",
        "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
        "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
        "\n",
        "        user_metrics = {'hits@5_count':hits_at_5_count,\n",
        "                          'hits@10_count':hits_at_10_count,\n",
        "                          'interacted_count': interacted_items_count_testset,\n",
        "                          'recall@5': recall_at_5,\n",
        "                          'recall@10': recall_at_10}\n",
        "        return user_metrics\n",
        "      except KeyError:\n",
        "        # Handle the KeyError gracefully, e.g., by returning default metrics or logging the error\n",
        "        print(f\"User with user_id {user_id} not found in the test set.\")\n",
        "        return {'hits@5_count': 0, 'hits@10_count': 0, 'interacted_count': 0, 'recall@5': 0, 'recall@10': 0}\n",
        "\n",
        "\n",
        "    # Function to evaluate the performance of model at overall level\n",
        "    def evaluate_model(self, model):\n",
        "\n",
        "        people_metrics = []\n",
        "\n",
        "        for idx, user_id in enumerate(list(interactions_test_indexed_df.index.unique().values)):\n",
        "            person_metrics = self.evaluate_model_for_user(model,user_id)\n",
        "            person_metrics['_person_id'] = user_id\n",
        "            people_metrics.append(person_metrics)\n",
        "\n",
        "        print('{0} users processed' .format(idx))\n",
        "\n",
        "        detailed_results_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
        "\n",
        "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "\n",
        "        global_metrics = {'modelName': model.get_model_name(),\n",
        "                          'recall@5': global_recall_at_5,\n",
        "                          'recall@10': global_recall_at_10}\n",
        "        return global_metrics, detailed_results_df\n",
        "\n",
        "model_evaluator = ModelEvaluator()"
      ],
      "metadata": {
        "id": "oj3uPXQoj0M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluating Content-Based Filtering model...')\n",
        "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)\n",
        "\n",
        "# # Move the user_id column to the first position\n",
        "# user_id_column = cb_detailed_results_df['_user_id']  # Extract the user_id column\n",
        "# cb_detailed_results_df = cb_detailed_results_df.drop(columns=['_user_id'])\n",
        "# cb_detailed_results_df.insert(0, '_user_id', user_id_column)\n",
        "\n",
        "print('\\nGlobal metrics:\\n{}' .format(cb_global_metrics))\n",
        "cb_detailed_results_df.head(10)"
      ],
      "metadata": {
        "id": "Rv9MUXgmlb91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_profiles.shape)\n",
        "print(tfidf_matrix.shape)"
      ],
      "metadata": {
        "id": "WM3phkegqU1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "15vsFWCIjvG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}