{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "MSa1f5Uengrz",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saketvaibhav7114/Book-Recommendation-System/blob/main/Book_Recommendation_System_(Unsupervised_Learning_Project).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Book Recommendation System\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Unsupervised\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Saket Vaibhav"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "During the last few decades, with the rise of Youtube, Amazon, Netflix, and many other such web services, recommender systems have taken more and more place in our lives. From e-commerce (suggest to buyers articles that could interest them) to online advertisement (suggest to users the right contents, matching their preferences), recommender systems are today unavoidable in our daily online journeys.\n",
        "\n",
        "A recommendation system helps an organization to create loyal customers and build trust with them by providing the products and services they desire. The recommendation system today is so powerful that it can handle the new customer who has visited the site for the first time. They recommend the products that are currently trending or highly rated, and they can also recommend the products that bring maximum profit to the company.\n",
        "\n",
        "### **Data Collection:**\n",
        "The foundation of any recommendation system is data. In this project, data collection involved gathering information about books, authors, user preferences, and historical reading patterns. The dataset for Book Recommendation System comprises three files:\n",
        "\n",
        "**Users**\n",
        "\n",
        "Contains the users IDs, Location & Age.\n",
        "\n",
        "\n",
        "**Books**\n",
        "\n",
        "Books are identified by their respective ISBN. Some content-based information is also given (Book-Title, Book-Author, Year-Of-Publication, Publisher), obtained from Amazon Web Services.\n",
        "\n",
        "\n",
        "**Ratings**\n",
        "Contains the book rating information expressed on a scale from 1-10 (higher values denoting higher appreciation). The data included details like book titles, genres, authors, user ratings, and textual descriptions.\n",
        "\n",
        "\n",
        "### **Data Preprocessing:**\n",
        "Data preprocessing involved tasks such as cleaning the data, handling missing values, and transforming textual descriptions into numerical representations through techniques like TF-IDF (Term Frequency-Inverse Document Frequency).\n",
        "\n",
        "\n",
        "### **Clustering Algorithms:**\n",
        "One of the key components of the recommendation system is the use of clustering algorithms. Unsupervised clustering methods, such as K-Means are applied to group books with similar characteristics. These clusters are created based on factors like genre, author, and book content. The goal is to identify patterns and associations among books that could aid in recommendations.\n",
        "\n",
        "### **Matrix Factorization:**\n",
        "Matrix factorization techniques, including Singular Value Decomposition (SVD) are employed to uncover latent factors that influence user preferences. By decomposing the user-item interaction matrix, these algorithms revealed hidden relationships between users and books. This information is then used to make personalized recommendations.\n",
        "\n",
        "### **Collaborative Filtering:**\n",
        "Collaborative filtering relies on the idea that users who have similar reading preferences will likely enjoy similar books. Collaborative filtering algorithms, such as user-based and item-based collaborative filtering, were implemented to generate recommendations based on user behavior and item similarity. This approach helped in fine-tuning the suggestions.\n",
        "\n",
        "### **Content-Based Filtering:**\n",
        "In addition to collaborative filtering, content-based filtering is used to improve the recommendation system's accuracy. This approach analyzed the textual descriptions of books and matched them with user preferences. Natural Language Processing (NLP) techniques were employed to extract meaningful features from the book descriptions and align them with user profiles.\n",
        "\n",
        "### **Evaluation Metrics:**\n",
        "To assess the performance of the Book Recommendation System, several evaluation metrics are employed. Common metrics included Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and precision-recall metrics. These measures helped gauge the accuracy and effectiveness of the recommendations provided to users."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/saketvaibhav7114/Book-Recommendation-System"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The world of literature is vast, with millions of books spanning various genres and subjects. Navigating this extensive library can be overwhelming for readers looking for their next captivating read. To address this challenge, a Book Recommendation System was developed. This system leverages the power of unsupervised learning algorithms to provide personalized book recommendations to users, enhancing their reading experience."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "import sklearn\n",
        "import warnings\n",
        "import random\n",
        "import sklearn\n",
        "import scipy\n",
        "import math\n",
        "import nltk\n",
        "import string\n",
        "\n",
        "# Tokenization\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Stopwords\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Stemming & Lemmatization\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# ML Model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from scipy.sparse.linalg import svds\n",
        "\n",
        "warnings.simplefilter('ignore')\n",
        "pd.set_option('display.max_colwidth', -1)"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ywe4DEDIsDoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Book Data\n",
        "book_data = pd.read_csv(\"/content/drive/MyDrive/Books.csv\")\n",
        "\n",
        "# Users Data\n",
        "users_data= pd.read_csv('/content/drive/MyDrive/Users.csv')\n",
        "\n",
        "# Ratings Data\n",
        "ratings_data = pd.read_csv(\"/content/drive/MyDrive/Ratings.csv\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "# Book Data\n",
        "book_data.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Users Data\n",
        "users_data.head()"
      ],
      "metadata": {
        "id": "-R9NWteUtN7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ratings Data\n",
        "ratings_data.head()"
      ],
      "metadata": {
        "id": "XOSEfBzYxTNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "# Book Data\n",
        "book_data.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.shape"
      ],
      "metadata": {
        "id": "xVQnNiuGxwEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.shape"
      ],
      "metadata": {
        "id": "2ZENFt3nx27W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "# Book Data\n",
        "book_data.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.info()"
      ],
      "metadata": {
        "id": "WpD37fA9yEKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.info()"
      ],
      "metadata": {
        "id": "cfAEewfiyGiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# Book Data\n",
        "book_data.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.duplicated().sum()"
      ],
      "metadata": {
        "id": "f6hLUXT-yhYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.duplicated().sum()"
      ],
      "metadata": {
        "id": "Z2v5ekZlyiGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "# Book Data\n",
        "book_data.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.isnull().sum()"
      ],
      "metadata": {
        "id": "CMCrxl9Dywet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.isnull().sum()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "# Book Data\n",
        "book_missing_value=book_data.isnull().sum()\n",
        "columns_with_missing_values = book_missing_value[book_missing_value > 0]      #  Filter columns with missing values\n",
        "\n",
        "# Calculate the percentage of missing values in each column\n",
        "total_rows = len(book_data)\n",
        "percentage_missing = (columns_with_missing_values / total_rows) * 100\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bar_plot = columns_with_missing_values.plot(kind='bar', color='lightcoral')\n",
        "plt.xlabel('Columns with Missing Value',fontsize=14)\n",
        "plt.ylabel('Number of Missing Values',fontsize=14)\n",
        "plt.title('Number of Missing Values in Book Dataset',fontsize=14)\n",
        "plt.xticks(rotation=0, ha='center',fontsize=10)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)"
      ],
      "metadata": {
        "id": "_hPLlUovy9t4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_missing_value=users_data.isnull().sum()\n",
        "columns_with_missing_values = users_missing_value[users_missing_value > 0]      #  Filter columns with missing values\n",
        "\n",
        "# Calculate the percentage of missing values in each column\n",
        "total_rows = len(book_data)\n",
        "percentage_missing = (columns_with_missing_values / total_rows) * 100\n",
        "\n",
        "# Create a bar chart\n",
        "plt.figure(figsize=(10, 6))\n",
        "bar_plot = columns_with_missing_values.plot(kind='bar', color='lightcoral')\n",
        "plt.xlabel('Columns with Missing Value',fontsize=14)\n",
        "plt.ylabel('Number of Missing Values',fontsize=14)\n",
        "plt.title('Number of Missing Values in User Dataset',fontsize=14)\n",
        "plt.xticks(rotation=0, ha='center',fontsize=14)\n",
        "plt.yticks(fontsize=10)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Display the percentage of missing values on top of bar\n",
        "for index, value in enumerate(columns_with_missing_values):\n",
        "    plt.text(index, value, f'{percentage_missing[index]:.2f}%', ha='center', va='bottom',fontsize=10)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2hK8zancUjcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:**The dataset is well-prepared for further analysis, as it contains no duplicated rows and some missing values which needs to be fixed either by using the fillna method or dropping the rows so that there is a clean and unique dataset for analysis. Most of the missing value is in age columns of users dataset. Most of the features are either objects or floats. If necessary, it needs to be converted into the required datatype. After the necessary cleaning, the dataset will be ready for preprocessing steps, allowing the focus to be on feature engineering and model development to achieve accurate predictions."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "# Book Data\n",
        "book_data.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.columns"
      ],
      "metadata": {
        "id": "N-2kGSWcmBkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.columns"
      ],
      "metadata": {
        "id": "0V1GHhBcmLMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "# Book Data\n",
        "book_data.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.describe().T"
      ],
      "metadata": {
        "id": "MoeKvFnwmk-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.describe().T"
      ],
      "metadata": {
        "id": "3qtPUgpkmqcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Description of each column in the `book_data` DataFrame :-\n",
        "\n",
        "1. `ISBN`: This column contains International Standard Book Number (ISBN) codes, which are unique identifiers for books. ISBNs are used to uniquely identify books worldwide.\n",
        "\n",
        "2. `Book-Title`: This column stores the titles of the books. It provides the names of the books in the dataset.\n",
        "\n",
        "3. `Book-Author`: This column contains the names of the authors of the books. It specifies the individuals or entities responsible for writing the books.\n",
        "\n",
        "4. `Year-Of-Publication`: This column represents the year in which each book was published. It indicates the release year of the books.\n",
        "\n",
        "5. `Publisher`: This column contains the names of the publishers of the books. It identifies the publishing companies responsible for producing and distributing the books.\n",
        "\n",
        "6. `Image-URL-S`, `Image-URL-M`, `Image-URL-L`: These columns store URLs (web addresses) of images associated with the books. They provide links to small, medium, and large-sized images of the book covers.\n",
        "\n",
        "Description of each column in the `users_data` DataFrame :-\n",
        "\n",
        "1. `User-ID`: This column contains unique identifiers for users. Each user is assigned a unique User-ID, which is used to distinguish one user from another.\n",
        "\n",
        "2. `Location`: This column stores information about the location of each user. It typically includes details such as the city, state or region, and sometimes additional location-specific information.\n",
        "\n",
        "3. `Age`: This column represents the age of each user. It provides information about the age of the users in the dataset.\n",
        "\n",
        "Description of each column in the `ratings_data` DataFrame :-\n",
        "\n",
        "1. `User-ID`: This column contains unique identifiers for users who have provided book ratings. Each user is assigned a unique User-ID, which is used to associate ratings with specific users.\n",
        "\n",
        "2. `ISBN`: This column contains International Standard Book Number (ISBN) codes, similar to the ISBN column in the `book_data` DataFrame. ISBNs uniquely identify books and are used to associate ratings with specific books.\n",
        "\n",
        "3. `Book-Rating`: This column stores the ratings provided by users for books. It represents the user's assessment or opinion of a particular book, typically on a numerical scale."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "# Book Data\n",
        "book_data.nunique()"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# User Data\n",
        "users_data.nunique()"
      ],
      "metadata": {
        "id": "trGH4Y1PnEZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ratings_data\n",
        "ratings_data.nunique()"
      ],
      "metadata": {
        "id": "EqCoDaitnLRa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data Cleaning of book dataset"
      ],
      "metadata": {
        "id": "8ZqdCzPVrnBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "book_data.rename(columns = {'Book-Title':'title', 'Book-Author':'author', 'Year-Of-Publication':'year', 'Publisher':'publisher'}, inplace=True)\n",
        "\n",
        "# droping the url\n",
        "book_data.drop(['Image-URL-S', 'Image-URL-M', 'Image-URL-L'], axis= 1, inplace= True)\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.info()"
      ],
      "metadata": {
        "id": "bFm-tQAestXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.isnull().sum()"
      ],
      "metadata": {
        "id": "yFGlxbTUsxOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nan values in book_author column\n",
        "book_data.loc[(book_data['author'].isnull()),: ]"
      ],
      "metadata": {
        "id": "WW2saRV3s7Kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nan values in publisher column\n",
        "book_data.loc[(book_data['publisher'].isnull()),: ]"
      ],
      "metadata": {
        "id": "uPCdRk0ptG2Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# getting unique value from 'year_of_publication' feature\n",
        "book_data['year'].unique()"
      ],
      "metadata": {
        "id": "UIYwLDSytSih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting rows with year column=\"DK Publishing Inc\"\n",
        "book_data[book_data['year'] == 'DK Publishing Inc']"
      ],
      "metadata": {
        "id": "jYrhiZfptiIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extracting rows with year column=\"Gallimard\"\n",
        "book_data[book_data['year'] == 'Gallimard']"
      ],
      "metadata": {
        "id": "lj2dXLbT53J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[187689]"
      ],
      "metadata": {
        "id": "-ygOCUGnfsUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[221678]"
      ],
      "metadata": {
        "id": "HM96CO4u_YrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[209538]"
      ],
      "metadata": {
        "id": "Z2R1sY23AUMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[220731]"
      ],
      "metadata": {
        "id": "nvOOp-J1_q21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Let's fix the column and make it in correct format as per our dataset."
      ],
      "metadata": {
        "id": "xkHfkUNjGdVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to fix mismatch data in feature 'book_title', 'book_author', ' year_of_publication', 'publisher'\n",
        "def replace_df_value(df, idx, col_name, val):\n",
        "  df.loc[idx, col_name] = val\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "Hx6botZkGNL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_df_value(book_data, 209538, 'title', 'DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)')\n",
        "replace_df_value(book_data, 209538, 'author', 'Michael Teitelbaum')\n",
        "replace_df_value(book_data, 209538, 'year', 2000)\n",
        "replace_df_value(book_data, 209538, 'publisher', 'DK Publishing Inc')\n",
        "\n",
        "replace_df_value(book_data, 221678, 'title', 'DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)')\n",
        "replace_df_value(book_data, 221678, 'author', 'James Buckley')\n",
        "replace_df_value(book_data, 221678, 'year', 2000)\n",
        "replace_df_value(book_data, 221678, 'publisher', 'DK Publishing Inc')\n",
        "\n",
        "replace_df_value(book_data, 220731,'title', \"Peuple du ciel, suivi de 'Les Bergers\")\n",
        "replace_df_value(book_data, 220731, 'author', 'Jean-Marie Gustave Le ClÃ?Â©zio')\n",
        "replace_df_value(book_data, 220731, 'year', 2003)\n",
        "replace_df_value(book_data, 220731, 'publisher', 'Gallimard')"
      ],
      "metadata": {
        "id": "BTgmCVVfGpvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[209538]"
      ],
      "metadata": {
        "id": "4H6140xzIhIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[221678]"
      ],
      "metadata": {
        "id": "K43aPKgsIkSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.loc[220731]"
      ],
      "metadata": {
        "id": "jY9B6a4XInWP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data['year'].unique()"
      ],
      "metadata": {
        "id": "iHNJm90_6RyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the datatype of year column from object to int\n",
        "book_data['year'] = book_data['year'].astype(int)\n"
      ],
      "metadata": {
        "id": "cDSkFSy86kcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.info()"
      ],
      "metadata": {
        "id": "P8l9MjVt5u-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data Cleaning of user dataset"
      ],
      "metadata": {
        "id": "Nf6OVBZHLiQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the column\n",
        "users_data.rename(columns = {'User-ID':'user_id', 'Location':'location', 'Age':'age'}, inplace=True)\n"
      ],
      "metadata": {
        "id": "EW2Ix73_SjZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_data.info()"
      ],
      "metadata": {
        "id": "HQLso6xAS7ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Data Cleaning of ratings dataset"
      ],
      "metadata": {
        "id": "zQ_HdOruXy2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renamimg the column\n",
        "ratings_data.rename(columns = {'User-ID':'user_id', 'Book-Rating':'rating'}, inplace=True)"
      ],
      "metadata": {
        "id": "SYfhmrMEXySO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data.info()"
      ],
      "metadata": {
        "id": "MKyq2-GjYHUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data['rating'].unique()"
      ],
      "metadata": {
        "id": "HSewyYltYXgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data['user_id'].value_counts()"
      ],
      "metadata": {
        "id": "9h3--EmrY1-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A big flaw with a problem statement in the rating dataset**\n",
        "\n",
        "If we take all the books and all the users for modeling, it will create a problem because we cannot consider a user who has only registered on the website or has only read one or two books. On such a user, we cannot rely to recommend books to others because we have to extract knowledge from data. So we will limit this number and we will take a user who has rated at least 200 books and also we will limit books and we will take only those books which have received at least 50 ratings from a user."
      ],
      "metadata": {
        "id": "lwMP-SmqgQKk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract users who has rated more than 200 books**\n"
      ],
      "metadata": {
        "id": "4zeVrI3Pg4Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = ratings_data['user_id'].value_counts() > 200"
      ],
      "metadata": {
        "id": "A9Avzed_gPJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = x[x].index  # user_ids\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "vNbuDmUNiSQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data = ratings_data[ratings_data['user_id'].isin(y)]"
      ],
      "metadata": {
        "id": "BIeMrXM3hMSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ratings_data.shape"
      ],
      "metadata": {
        "id": "HvrZ_KrciI7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So 900 users are there who have given 5.2 lakh rating"
      ],
      "metadata": {
        "id": "vmR3oyd-zIKw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calculate Average Ratings of Each Book"
      ],
      "metadata": {
        "id": "YHZjs1omw48e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "number_rating = ratings_data.groupby('ISBN').count()['rating'].reset_index()\n",
        "number_rating.rename(columns= {'rating':'number_of_ratings'}, inplace=True)\n",
        "number_rating"
      ],
      "metadata": {
        "id": "WBU6eLnh1ohs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_rating=ratings_data.merge(number_rating,on='ISBN')\n",
        "final_rating\n"
      ],
      "metadata": {
        "id": "c9AGy6lDtiOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract books that have received more than 50 ratings.\n",
        "\n"
      ],
      "metadata": {
        "id": "1QZ-JGaXzwOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_rating = final_rating[final_rating['number_of_ratings'] >= 50]"
      ],
      "metadata": {
        "id": "GegSY_G31yes"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop Duplicated Row\n",
        "final_rating.drop_duplicates(['user_id','ISBN'], inplace=True)"
      ],
      "metadata": {
        "id": "PHqVPUNw4A_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merge ratings with books_data & user_data**\n",
        "\n",
        "> Merge ratings with books on basis of ISBN so that we will get the rating of each user on each book id and the user who has not rated that book id the value will be zero.\n",
        "\n",
        "> Merge ratings_with_books on basis of user_id so that we will get the rating of each user on each book id and the user who has not rated that book id the value will be zero\n",
        "\n"
      ],
      "metadata": {
        "id": "uxf-PpZQvDJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_with_books = final_rating.merge(book_data, on='ISBN')\n"
      ],
      "metadata": {
        "id": "lF2ItEn7vQ8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Merge Final Rating Dataset with the Users Dataset**"
      ],
      "metadata": {
        "id": "i3YVSzPNGMOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users=rating_with_books.merge(users_data,on='user_id')\n"
      ],
      "metadata": {
        "id": "J0Ce7yIeCW1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.head()"
      ],
      "metadata": {
        "id": "8FT1vKU_G-78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract 'country' values from 'location' column\n",
        "rating_book_users['country'] = rating_book_users['location'].str.split(',').str[-1].str.strip()\n",
        "\n",
        "# Drop the 'location' column\n",
        "rating_book_users.drop(columns=['location'], inplace=True)"
      ],
      "metadata": {
        "id": "-h_sXIAgF_6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users['country'].unique()"
      ],
      "metadata": {
        "id": "i-rwQI5lrHbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'usa' with 'us',double quotes (\") & 'n/a' with 'nan' in 'country' column\n",
        "rating_book_users['country'] = rating_book_users['country'].str.replace('usa','us').replace('n/a',np.nan).replace('', np.nan)\n",
        "\n",
        "# Display the modified 'country' column\n",
        "rating_book_users['country'].unique()"
      ],
      "metadata": {
        "id": "5diOKOVGrNcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.tail()"
      ],
      "metadata": {
        "id": "vodb_3xIC5Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.shape"
      ],
      "metadata": {
        "id": "8lZ98F60H7in"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we have a dataset with that user who has rated more than 200 books and books that received more than 50 ratings. The shape of the final dataframe is 59850 rows and 10 columns."
      ],
      "metadata": {
        "id": "xeqgSEcU-UKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.info()"
      ],
      "metadata": {
        "id": "zseQ5Bo6CYyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.loc[41803]"
      ],
      "metadata": {
        "id": "rwCUAOW5DTB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:**-Several data manipulation steps are performed on data frames (`book_data`, `users_data`, `ratings_data`) for preprocessing and enhancing data quality:\n",
        "\n",
        "1. **Column Renaming (book_data, users_data, ratings_data):** Column names are standardized and renamed for consistency, making it easier to work with the data.\n",
        "\n",
        "2. **Column Removal (book_data):** Image URL columns are dropped from the `book_data` frame as they are not relevant to the analysis.\n",
        "\n",
        "3. **Data Cleansing (book_data):** A custom function `replace_df_value` is applied to fix mismatched data in specific columns.\n",
        "\n",
        "4. **Data Type Conversion (book_data):** The 'year' column's data type is changed from object to integer for proper data handling.\n",
        "\n",
        "5. **Data Filtering (ratings_data):** Users who have rated more than 200 books are extracted from `ratings_data`, and the resulting data frame is filtered accordingly.\n",
        "\n",
        "6. **Rating Aggregation (ratings_data):** The number of ratings for each book is calculated and stored in a new column called 'number_of_ratings.'\n",
        "\n",
        "7. **Data Merging (final_rating):** The calculated number of ratings is merged with the `ratings_data` frame to enhance book data with the number of ratings.\n",
        "\n",
        "8. **Data Filtering (final_rating):** Books that have received more than 50 ratings are selected, and duplicate rows are removed.\n",
        "\n",
        "9. **Data Merging (rating_with_books):** The enhanced `final_rating` data is merged with book data to associate ratings with book details.\n",
        "\n",
        "10. **Data Merging (rating_book_users):** User data is merged with the rating and book data to create a comprehensive dataset.\n",
        "\n",
        "11. **Location Processing (rating_book_users):** The 'location' column is used to extract 'country' values and replace specific values for consistency.\n",
        "\n",
        "These manipulations prepare the data for further analysis while ensuring data consistency and quality."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "plt.figure(figsize=(14,6))\n",
        "ax=sns.countplot(x=\"rating\",palette = 'Paired',data= rating_book_users)\n",
        "plt.title('Count of Each Ratings',fontsize=15)\n",
        "plt.xlabel('Rating',fontsize=15)\n",
        "plt.ylabel('Count',fontsize=15)\n",
        "plt.xticks(fontsize=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "# Add value annotations to the bars\n",
        "for p in ax.patches:\n",
        "    ax.annotate(format(p.get_height(), '.0f'),\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha='center', va='center', fontsize=10, color='black', xytext=(0, 5),\n",
        "                textcoords='offset points')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:- Countplot was chosen because it is a suitable and effective choice for visualizing the distribution of ratings, allowing viewers to quickly grasp how ratings are distributed across the dataset."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans: **\n",
        "\n",
        "1. **Common Ratings:** From the chart, it is evident that ratings 7 to 10 are the most common suggesting that a significant number of users have rated books with these scores.\n",
        "\n",
        "2. **Positive Ratings:** Ratings 8 and 10, being on the higher end of the scale, are indicative of positive sentiment.\n",
        "\n",
        "3. **Few Low Ratings:** Ratings below 5 (1 to 4) are relatively less common, indicating that users are less likely to give very low ratings to books.\n"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** The insights gained from the chart can indeed help create a positive business impact, but there are also insights that may have some potential negative implications. Let's examine both aspects:\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "> **Enhanced Recommendation Systems:** Understanding the distribution of ratings can improve the accuracy of recommendation systems. Recommending books with ratings similar to those that users have given high ratings to can result in more successful recommendations, potentially boosting book sales.\n",
        "\n",
        "**Negative Business Impact:**\n",
        "\n",
        "> **Positive Bias:** The fact that users tend to give higher ratings may lead to a positive bias in the dataset. If users are more inclined to rate books positively, it can be challenging to differentiate truly exceptional books from those that are merely good. This might result in users not receiving accurate recommendations that match their specific tastes."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 \"User Age Profile\""
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(15,6))\n",
        "sns.distplot(rating_book_users['age'])\n",
        "plt.title('Age Distribution\\n',fontsize=15)\n",
        "plt.xlabel('Age',fontsize=15)\n",
        "plt.ylabel('Count',fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UdEpXJaeu-DN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** The data being visualized consists of numerical values (ages). Histograms are particularly useful for visualizing the distribution and shape of numerical data."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Common Age Ranges:-** There are relatively more users in age ranges of 25-35 who are reading the books & rating them effectively.\n",
        "\n",
        "> **Skewness:** The chart's shape indicates the age distribution is positively skewed.\n",
        "\n",
        "> **Outliers:** The chart also highlight outliers in the age distribution, which needs to be treated before building the model."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The insights gained from the age distribution chart can have both positive and potentially challenging implications for businesses.\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        ">  **Understanding User Demographics:** The age distribution chart helps businesses gain insights into the demographics of their user base. This understanding is valuable for tailoring marketing strategies and content to specific age groups thus allowing for personalized recommendations and experiences.\n",
        "\n",
        "**Challenges and Potential Negative Impact:**\n",
        "\n",
        "> **Age-Related Content:** While understanding the predominant age group is valuable, it may also pose challenges. If a business's content or products are primarily tailored to one age group, it may struggle to attract or retain users from other age segments.\n",
        "\n",
        "> **Market Saturation:** If the age distribution shows a saturation of a particular age group, it may imply that the business has already tapped into a saturated market, making it harder to acquire new customers within that age range."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3-\"Age Distribution of Book Rating Users\"\n",
        "\n"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(rating_book_users['age'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X1MsfPczvU2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** A boxplot displays essential summary statistics, such as the median, quartiles (25th and 75th percentiles), and potential outliers, all of which provide a quick overview of the data's central tendency and spread."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-**\n",
        "\n",
        "1. **Central Tendency**: The median age gives an insight into the typical or average age of book rating users.\n",
        "\n",
        "2. **Spread of Ages**: The length of the box (interquartile range, IQR) shows the spread of ages between the 25th percentile (Q1) and the 75th percentile (Q3). A longer box indicates a wider range of ages among users.\n",
        "\n",
        "3. **Outliers**: Some data points beyond the whiskers are potential outliers."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The insights gained from analyzing the age distribution of book rating users can indeed have both positive and potentially negative impacts on a business, depending on how they are interpreted and acted upon. Here's a breakdown of how these insights can influence business decisions and outcomes:\n",
        "\n",
        "**Positive Business Impacts**:\n",
        "\n",
        ">  **Customer Engagement**: Age insights can aid in creating personalized customer experiences. Tailoring recommendations and promotions based on age can enhance user engagement and satisfaction.\n",
        "\n",
        "**Potential Negative Impacts**:\n",
        "\n",
        "> **Competitive Advantage**: Competitors who effectively target underrepresented age groups can gain a competitive advantage. If the target business doesn't adapt, it could lose market share."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "filtered_data = rating_book_users[rating_book_users['year'] != 0]\n",
        "\n",
        "sns.boxplot(x=filtered_data['year'])\n",
        "plt.xlabel('Year')\n",
        "plt.title('Distribution of Years in Book Ratings (Excluding Year = 0)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: A boxplot provides a clear summary of the distribution, including the median , quartiles, and potential outliers. This makes it easy to understand the central tendency and spread of the 'year' data."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Central Tendency**: The median year, represented by the line inside the box gives an idea of the central or typical year associated with the book ratings in your dataset.\n",
        "\n",
        "> **Spread of Years**: The boxplot shows the interquartile range (IQR), which is the range between the 25th and 75th percentiles. It provides information about the spread of years in which books were rated. A larger IQR suggests a broader range of years."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** The insights gained from the boxplot of the 'year' variable can potentially lead to both positive and negative business impacts, depending on how they are interpreted and acted upon.\n",
        "\n",
        "**Positive Business Impacts**:\n",
        "\n",
        ">  **Identifying Popular Years**: The boxplot shows a concentration of book ratings in specific range of years & businesses can use this information to promote books from those years, capitalize on nostalgia, or create marketing campaigns centered around popular historical content.\n",
        "\n",
        "**Potential Negative Impacts**:\n",
        "\n",
        ">  **Narrow Focus**: Overemphasizing a specific era or year range due to its popularity in the data may limit the diversity of content offered. This could result in alienating users who have different interests and preferences.\n",
        "\n",
        ">  **Market Saturation**: A strong concentration of ratings in a particular time period, might indicate market saturation for books from that era. Overinvesting in content from that period could lead to diminishing returns."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "sns.boxplot(x=rating_book_users['number_of_ratings'])\n",
        "plt.xlabel('Number of Ratings')\n",
        "plt.title('Distribution of Number of Ratings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** A boxplot provides a clear summary of the distribution, including the median, quartiles, and potential outliers. This makes it easy to understand the central tendency and spread of the 'number_of_ratings' data."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> **Central Tendency:** The boxplot can help identify the median number of ratings, which represents the typical or central value for the number of ratings. This gives you an idea of the average level of user engagement with the books in the dataset.\n",
        "\n",
        "> **Spread of Ratings:** The length of the box (interquartile range, IQR) provides information about the spread of the number of ratings. A larger IQR suggests a wider range of ratings, while a smaller IQR indicates a more concentrated distribution.\n",
        "\n",
        "> **Outliers:** Any data points beyond the whiskers of the plot are potential outliers. These outliers help us understand if there are books with exceptionally high or low numbers of ratings, which might be influential or unusual in the dataset."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** The insights gained from analyzing the distribution of the 'number_of_ratings' variable can have a significant impact on business decisions, both positive and potentially negative, depending on how they are interpreted and acted upon.\n",
        "\n",
        "**Positive Business Impacts**:\n",
        "\n",
        "> **Identifying Popular Content**: Identifying books with a high number of ratings can help businesses recognize their most popular or well-received content. This knowledge can be used to highlight and promote these books, potentially leading to increased sales and positive customer experiences.\n",
        "\n",
        "> **Content Recommendation**: Understanding the distribution of ratings can improve content recommendation algorithms. Recommending books with a similar number of ratings to users who have shown interest in certain books can enhance user engagement and satisfaction.\n",
        "\n",
        "**Potential Negative Impacts**:\n",
        "\n",
        ">  **Neglecting Niche Content**: Overemphasis on books with high ratings and a large number of ratings may lead to neglecting niche or less popular content. This could result in missed opportunities to cater to specific audience segments and may limit diversity in your offerings."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6 \"Distribution of Ratings\""
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "sns.boxplot(x=rating_book_users['rating'])\n",
        "plt.xlabel('Rating')\n",
        "plt.title('Distribution of Ratings')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** The Box Plot is chosen to check whether there is any outlier in the rating columns or not."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** There is no outliers in the rating columns of the dataset."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7 \"Top 20 Prolific Authors\""
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.figure(figsize=(15,6))\n",
        "ax=sns.countplot(data=rating_book_users, y=\"author\", palette = 'Paired', order=rating_book_users['author'].value_counts().index[0:20])\n",
        "plt.title(\"Top 20 author with number of books\",fontsize=15)\n",
        "plt.xlabel(\"Count of Books\",fontsize=15)\n",
        "plt.ylabel(\"Author Name\",fontsize=15)\n",
        "\n",
        "# Add values on top of each bar\n",
        "for p in ax.patches:\n",
        "    width = p.get_width()\n",
        "    plt.text(width + 40, p.get_y() + p.get_height() / 2, f'{int(width)}',\n",
        "             ha='center', va='center', fontsize=10, color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** A horizontal bar chart is well-suited for showcasing the top authors and their book counts."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Prolific Authors**: Nora Roberts have written the most books.\n",
        "\n",
        "* **Author Ranking**: The information showing the ranking of top authors based on the number of books they've written can be valuable for understanding the hierarchy of author contributions in the dataset."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans:- The horizontal bar chart showcasing the top authors with the highest number of books can indeed have a positive business impact.\n",
        "\n",
        "**Positive Business Impacts**:\n",
        "\n",
        "* **Content Promotion**: Identifying prolific authors allows us to strategically promote their books. This can lead to increased sales and revenue, especially if these authors have a loyal following.\n",
        "\n",
        "* **Personalized Recommendations**: Insights about top authors can inform personalized content recommendations for users who have shown interest in their works. This can enhance user engagement and satisfaction.\n",
        "\n",
        "* **Author Partnerships**: If some authors are exceptionally prolific and popular, there may be opportunities to collaborate with them on exclusive content or promotions, which can be mutually beneficial.\n",
        "\n",
        "**Potential Negative Impacts**:\n",
        "\n",
        "* **Neglecting Emerging Talent**: Overemphasizing prolific authors may lead to overlooking emerging or lesser-known talent. This could limit our ability to diversify our content and discover new bestsellers.\n",
        "\n",
        "* **Content Diversity**: If a few authors dominate the list, it may indicate a lack of content diversity. Overreliance on a small group of authors can lead to content fatigue among users and potentially hinder growth."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8 \"Top 20 Publishers by Number of Books Published\""
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(15, 6))\n",
        "ax = sns.countplot(data=rating_book_users, y=\"publisher\", palette='Paired',\n",
        "                   order=rating_book_users['publisher'].value_counts().index[0:20])\n",
        "\n",
        "# Set the title\n",
        "plt.title(\"Top 20 Publishers with the number of books published\", fontsize=15)\n",
        "plt.xlabel(\"Number of Books\", fontsize=15)\n",
        "plt.ylabel(\"Publishers Name\", fontsize=15)\n",
        "\n",
        "# Adding values of each bar\n",
        "for p in ax.patches:\n",
        "    width = p.get_width()\n",
        "    plt.text(width + 80, p.get_y() + p.get_height() / 2, f'{int(width)}',\n",
        "             ha='center', va='center', fontsize=10, color='black')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans**:- Horizontal bar charts are effective for comparing the frequency or count of different categories (in this case, publishers) because they allow for easy visual comparison of values."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The horizontal bar chart displaying the top 20 publishers with the highest number of books published provides several insights:\n",
        "\n",
        "* **Prolific Publishers**: The insight helps us quickly see which publishers are the most prolific in terms of book production. It clearly identifies that Ballantine Books have published the highest number of books.\n",
        "\n",
        "* **Publisher Ranking**: The ranking of top publishers based on the number of books they've published can be valuable for understanding the hierarchy of publisher contributions.\n",
        "\n",
        "These insights can be valuable for decision-making and strategy development, particularly in content curation, marketing, and partnerships."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** The insights gained from the horizontal bar chart showcasing the top publishers can have both positive and potentially negative business impacts, depending on how they are interpreted and acted upon.\n",
        "\n",
        "**Positive Business Impacts**:\n",
        "\n",
        "* **Content Promotion**: Identifying prolific publishers allows us to strategically promote their books, potentially leading to increased sales and revenue, especially if these publishers have a strong reputation and a loyal readership.\n",
        "\n",
        "* **Marketing Strategies**: The chart can guide marketing strategies by focusing efforts on books from the most prolific publishers. This can optimize marketing budgets and improve return on investment (ROI).\n",
        "\n",
        "\n",
        "**Potential Negative Impacts**:\n",
        "\n",
        "* **Content Over-Reliance**: Overemphasizing books from a few prolific publishers may lead to over-reliance on their content. If these publishers face challenges or reduce their production, it could negatively impact your business's content portfolio.\n",
        "\n",
        "* **Limited Diversity**: If a small group of publishers dominates the list, it may indicate a lack of content diversity. Overreliance on a limited number of publishers may lead to content fatigue among users and limit the appeal of your offerings."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 \"Top 15 Books by Number of Ratings\""
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Create a countplot for the top 15 books based on the number of ratings\n",
        "ax = sns.countplot(y=\"title\", palette='Paired', data=rating_book_users, order=rating_book_users['title'].value_counts().index[0:15])\n",
        "plt.title(\"Top 15 Books by Number of Ratings\", fontsize=15)\n",
        "plt.xlabel(\"Total Number of Ratings Given\", fontsize=15)\n",
        "plt.ylabel(\"Book Title\", fontsize=15)\n",
        "plt.xticks(fontsize=10)\n",
        "plt.yticks(fontsize=8)\n",
        "\n",
        "# Adding values on top of each bar\n",
        "for p in ax.patches:\n",
        "    width = p.get_width()\n",
        "    plt.text(width + 7, p.get_y() + p.get_height() / 2, f'{int(width)}',\n",
        "             ha='center', va='center', fontsize=10, color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "c9lDuasX28e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** Horizontal bar charts are effective for comparing the frequency or count of different categories (in this case, book titles) because they allow for easy visual comparison of values."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** The horizontal bar chart displaying the top 15 books based on the number of ratings provides several insights:\n",
        "\n",
        "* **Most Popular Books**: Wild Animus has received the highest number of rating followed by The Lovely Bones- A Novel. This insight helps us quickly see which books are the most popular and widely read among users.\n",
        "\n",
        "*  **Book Ranking**: The chart shows the ranking of these top books based on the number of ratings they've received. This information can be valuable for understanding the hierarchy of book preferences in the dataset.\n",
        "\n",
        "* **Top 15 Focus**: By limiting the chart to the top 15 books, it focuses the viewer's attention on the most significant contributors to the dataset in terms of ratings.\n",
        "\n",
        "These insights can be valuable for decision-making, marketing, content recommendation, and user engagement strategies."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** The bar chart showcasing the top-rated books can have both positive and potentially negative business impacts:\n",
        "\n",
        "**Positive Business Impacts**:\n",
        "\n",
        "* **Content Promotion**: Identifying the most popular books based on ratings allows for strategic promotion of these books. This can lead to increased sales and revenue, especially if these books have a strong following.\n",
        "\n",
        "* **Marketing Strategies**: The chart can guide marketing strategies by focusing efforts on books with the highest number of ratings. This can optimize marketing budgets and improve ROI.\n",
        "\n",
        "**Potential Negative Impacts**:\n",
        "\n",
        "* **Overlooking Niche Content**: Overemphasizing top-rated books may lead to overlooking niche or lesser-known content that caters to specific audience segments. Neglecting these segments could limit growth opportunities.\n",
        "\n",
        "\n",
        "* **Market Saturation**: If the top-rated books are already widely read and saturated in the market, further promotion may not lead to significant growth and could result in diminishing returns."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 \"Year-wise Book Publication Statistics\""
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Create a countplot for the number of books published each year\n",
        "ax=sns.countplot(data=rating_book_users, x=\"year\", palette='Paired', order=sorted(rating_book_users['year'].unique()))\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title(\"Number of Books Published Each Year\")\n",
        "plt.xlabel(\"Year\",fontsize=15)\n",
        "plt.ylabel(\"Number of Books\",fontsize=15)\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# Add values on top of each bar\n",
        "for p in ax.patches:\n",
        "  ax.annotate(f'{int(p.get_height())}', (p.get_x() + p.get_width() / 2, p.get_height()+30),\n",
        "                ha='center', va='bottom', fontsize=10, color='black')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dx5vEbsp5Xtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-**The objective is to show how many books were published in each year, which is essentially counting the frequency of each category (year). Countplots are designed for this purpose."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Yearly Publication Trends:** The maximum number of books is published in the year 2000, followed by the year 1999. However, there was a drastic decline in books published in 2004.\n",
        "\n",
        "\n",
        "* **Historical Context:** There are spikes or drops in publication counts during specific years, which could be related to historical events, technological advancements, or cultural shifts.\n",
        "\n",
        "\n",
        "* **Steady Growth or Decline:** By examining the overall direction of the bars, we can say that over the years, the number of books published has steadily increased.\n",
        "\n",
        "\n",
        "* **Turning Points:** The year 1992 marked a significant change in the publication trend because of the sudden increase in books published after a period of slow growth.\n",
        "\n"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The chart showing the number of books published each year can indeed help create a positive business impact, but they can also highlight potential challenges and negative growth factors.\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "* **Market Demand:** Understanding the trends in publication counts can provide insights into market demand for certain types of books. If specific genres or topics consistently show increased publication counts, publishers can tailor their offerings to meet this demand, potentially resulting in higher sales.\n",
        "\n",
        "**Negative Growth Factors:**\n",
        "\n",
        "* **Overcrowded Market:** A significant increase in publication counts without a corresponding increase in readership or sales can lead to an overcrowded market. This can make it difficult for individual books to stand out and negatively impact sales and profitability.\n",
        "\n",
        "* **Quality vs. Quantity:** A focus on increasing publication counts without maintaining quality can lead to negative growth. Readers may become disillusioned with a flood of low-quality books, damaging the publisher's reputation and long-term prospects."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11 \"User Engagement Trends: A Decade of Book Ratings\""
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# Filter out rows where 'year' is not equal to 0\n",
        "filtered_final_data = rating_book_users[rating_book_users['year'] != 0]\n",
        "\n",
        "sns.lineplot(x='year', y='number_of_ratings', data=filtered_final_data)\n",
        "\n",
        "plt.title(\"Number of Ratings Over the Years\", fontsize=15)\n",
        "plt.xlabel(\"Year\", fontsize=15)\n",
        "plt.ylabel(\"Number of Ratings\", fontsize=15)\n",
        "plt.xticks(range(min(filtered_final_data['year']), max(filtered_final_data['year'])+1, 5))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Line plot is appropriate for visualizing the temporal trends in the number of ratings, helping to identify patterns, growth, or changes in user engagement with books over the years."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* An upward trend in the line suggests that more users have been rating books over time, which can indicate increased user engagement with the platform or a growing user base.\n",
        "\n",
        "* Conversely, a flat or declining trend in the number of ratings might signal a plateau in user engagement or a decrease in the platform's popularity. This could be a concern for the platform's administrators, and they might need to explore strategies to re-engage users.\n",
        "\n",
        "* A sudden surge in ratings in a specific year might be linked to a highly anticipated book release or a successful marketing campaign. Conversely, a sharp drop might result from a technical issue or a change in platform policies."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ans: The number of ratings over the years can indeed help create a positive business impact. However, there are also insights that, if not addressed appropriately, could potentially lead to negative growth.\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "* **Strategic Planning:** Insights into long-term trends can inform strategic planning. For example, if the data shows consistent growth, businesses can allocate resources for scaling their platform, improving user experience, and expanding their user base.\n",
        "\n",
        "* **Optimizing Marketing Efforts:** Recognizing seasonal or cyclical patterns can help businesses optimize their marketing efforts. They can plan marketing campaigns and promotions around peak periods of user engagement to maximize their impact.\n",
        "\n",
        "**Negative Growth Factors:**\n",
        "\n",
        "* **Declining Trends:** A consistent decline in the number of ratings over the years could indicate a loss of interest or engagement among users. This negative trend can result in reduced user retention, declining advertising revenue, and a less vibrant user community. It's essential for businesses to address this issue promptly."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12 \"Global Authors Diversity: Insights by Country\""
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "# Group the data by 'country' and count the unique 'author' values in each group\n",
        "country_author_counts = rating_book_users.groupby('country')['author'].nunique()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(14, 7))\n",
        "ax=country_author_counts.plot(kind='bar',color='skyblue')\n",
        "plt.title('Number of Unique Authors by Country',fontsize=15)\n",
        "plt.xlabel('Country',fontsize=15)\n",
        "plt.ylabel('Number of Unique Authors',fontsize=15)\n",
        "plt.xticks(rotation=90,fontsize=11)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Add value annotations to the bars\n",
        "for i, v in enumerate(country_author_counts):\n",
        "  ax.text(i, v + 1, str(v), ha='center', va='bottom', fontsize=11)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** Bar plots are effective for comparing categories or groups by displaying the count or value associated with each category as a separate bar. This allows for a straightforward comparison of the number of unique authors across countries"
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The chart allows us to identify countries with a high number of unique authors. These countries may be considered literary hubs or have a strong presence of authors.\n",
        "\n",
        "* US, UK & Canada dominate the chart among the most authors, while European countries such as Sweden, Denmark, and Austria contributed the least number of authors.\n",
        "\n",
        "* **Content Localization:** If US,UK & Canada have a high number of unique authors, it may indicate a rich source of content in specific languages or genres. This can be valuable for content localization strategies."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** Visualizing the number of unique authors by country can indeed help create a positive business impact in various ways. However, there are also potential challenges and negative growth factors that need to be addressed strategically.\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "* **Market Expansion:** Identifying regions with a significant number of unique authors can lead to market expansion opportunities. Businesses can target these regions for user acquisition and content partnerships, potentially increasing their user base and revenue.\n",
        "\n",
        "* **Content Localization:** Recognizing countries with prolific authorship can inform content localization strategies. Translating and promoting books from these regions can attract a broader international audience and boost sales.\n",
        "\n",
        "**Negative Growth Factors:**\n",
        "\n",
        "1. **Overreliance on Specific Regions:**  Overreliance on a single market can be risky if it experiences economic downturns or other challenges.\n",
        "\n",
        "2. **Lack of Diversity in Content:** While a high number of authors from specific countries may be advantageous, it could lead to a lack of diversity in the content available. Readers may seek a broader range of perspectives and genres."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13 \"Global Publisher Diversity: Insights by Country\""
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "\n",
        "# Group the data by 'country' and count the unique 'publisher' values in each group\n",
        "country_publisher_counts = rating_book_users.groupby('country')['publisher'].nunique()\n",
        "\n",
        "# Create a bar plot\n",
        "plt.figure(figsize=(14, 7))\n",
        "ax = country_publisher_counts.plot(kind='bar', color='skyblue')\n",
        "plt.title('Number of Unique Publishers by Country', fontsize=15)\n",
        "plt.xlabel('Country', fontsize=15)\n",
        "plt.ylabel('Number of Unique Publishers', fontsize=15)\n",
        "plt.xticks(rotation=90,fontsize=11)\n",
        "\n",
        "# Add value annotations to the bars\n",
        "for i, v in enumerate(country_publisher_counts):\n",
        "    ax.text(i, v + 0.1, str(v), ha='center', va='bottom', fontsize=11)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** Bar plots are effective for comparing categories or groups by displaying the count or value associated with each category as a separate bar. This allows for a straightforward comparison of the number of unique publishers across countries."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Regional Publishing Concentration:** The chart allows us to identify countries with a high number of unique publishers. These countries may be considered publishing hubs or have a strong presence of publishers contributing to the dataset.\n",
        "\n",
        "* US, UK & Canada dominates the chart among the most publishers while European Countries such as Denmark, Austria & Sweden contribute least number of publishers .\n",
        "\n",
        "* **Content Localization:** If US,UK & Canada have a high number of unique authors, it may indicate a rich source of content in specific languages or genres. This can be valuable for content localization strategies."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** Visualizing the number of unique publishers by country can indeed help create a positive business impact in several ways. However, there are potential challenges and negative growth factors that businesses should be aware of and address strategically.\n",
        "\n",
        "**Positive Business Impact:**\n",
        "\n",
        "* **Market Expansion:** Identifying regions with a significant number of unique publishers can lead to market expansion opportunities. Businesses can target these regions for partnerships, content acquisition, and user engagement, potentially increasing their user base and revenue.\n",
        "\n",
        "* **Content Variety:** Recognizing countries with diverse publisher presence can enhance content variety and quality. Users may find a wider range of genres, languages, and perspectives, which can attract and retain a more diverse readership.\n",
        "\n",
        "**Negative Growth Factors:**\n",
        "\n",
        "* **Overreliance on Specific Regions:**-Overreliance on a single market can be risky if it experiences economic downturns or other challenges.\n",
        "\n",
        "* **Competition with Local Publishers:** Targeting regions with active publisher presence may involve competition with well-established local publishers. Understanding local market dynamics and competitive strategies is crucial to succeed in such scenarios."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = rating_book_users.corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title(\"Correlation Heatmap of rating_book_users\", fontsize=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** A correlation heatmap is particularly useful when we have multiple numerical variables in our dataset and we want to explore the relationships between all of them simultaneously. It provides a comprehensive view of how variables are related to each other."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** None of the variables are correlated with each other suggesting no multicollinearity."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "sns.pairplot(rating_book_users)"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** A pairplot is a grid of scatterplots that displays pairwise relationships between numerical variables. Each scatterplot in the grid shows the relationship between two variables, allowing you to visualize correlations and distributions."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** Along the diagonal of the pairplot, histograms or density plots show the distribution of each variable from which we can assess whether variables follow normal distributions or exhibit skewness."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hypothetical Statement 1:** The average age of users from the United States ('USA') is higher than the average age of users from Canada ('Canada').\n",
        "\n",
        "**Hypothetical Statement 2:** The average age of users who rated books with a rating of 5 is higher than the average age of users who rated books with a rating less than 5.\n",
        "\n",
        "**Hypothetical Statement 3:** The average number of ratings for books with a rating of 5 is significantly higher than the average number of ratings for books with a rating less than 5."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** The average age of users from the USA is equal to the average age of users from Canada.\n",
        "\n",
        "**Alternative Hypothesis (H1):** The average age of users from the USA is not equal to the average age of users from Canada."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Separate the data for users from the USA and Canada\n",
        "age_usa = rating_book_users[rating_book_users['country'] == 'us']['age'].dropna()\n",
        "age_canada = rating_book_users[rating_book_users['country'] == 'canada']['age'].dropna()\n",
        "\n",
        "# Perform a t-test\n",
        "t_statistic, p_value = stats.ttest_ind(age_usa, age_canada, alternative='two-sided')\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print results\n",
        "print(\"t-statistic:\", t_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "if p_value < alpha:\n",
        "  print(\"Reject the null hypothesis: The average age of users from the USA is not equal to the average age of users from Canada.\")\n",
        "else:\n",
        "  print(\"Fail to reject the null hypothesis: The average age of users from the USA is equal to the average age of users from Canada.\")"
      ],
      "metadata": {
        "id": "BxjxG2ZxaAPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test are performed to find P-value"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test is commonly used to compare the means of two samples or groups to assess whether the observed difference is statistically significant or if it could have occurred by chance."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** The average age of users who rated books with a rating of 5 is equal to the average age of users who rated books with a rating less than 5.\n",
        "\n",
        "**Alternative Hypothesis (H1):** The average age of users who rated books with a rating of 5 is not equal to the average age of users who rated books with a rating less than 5."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Separate the data for users who rated books with a rating of 5 and users who rated books with a rating less than 5\n",
        "age_rating_5 = rating_book_users[rating_book_users['rating'] == 5]['age'].dropna()\n",
        "age_rating_less_than_5 = rating_book_users[rating_book_users['rating'] < 5]['age'].dropna()\n",
        "\n",
        "# Perform a one-tailed t-test (greater)\n",
        "t_stat, p_value = stats.ttest_ind(age_rating_5, age_rating_less_than_5, alternative='two-sided')\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print results\n",
        "print(\"t-statistic:\", t_stat)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "if p_value < alpha:\n",
        "  print(\"Reject the null hypothesis: The average age of users who rated books with a rating of 5 is not equal\\\n",
        "        \\nto average age of users who rated books with a rating less than 5.\")\n",
        "\n",
        "else:\n",
        "  print(\"Fail to reject the null hypothesis: The average age of users who rated books with a rating of 5 is equal\\\n",
        "        \\nto the average age of users who rated books with a rating less than 5.\")\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test are performed to find P-value"
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test is commonly used to compare the means of two samples or groups to assess whether the observed difference is statistically significant or if it could have occurred by chance."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** The average number of ratings for books with a rating of 5 is equal to the average number of ratings for books with a rating less than 5.\n",
        "\n",
        "**Alternative Hypothesis (H1):** The average number of ratings for books with a rating of 5 is higher than the average number of ratings for books with a rating less than 5."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Separate the data for books with a rating of 5 and books with a rating less than 5\n",
        "num_ratings_rating_5 = rating_book_users[rating_book_users['rating'] == 5]['number_of_ratings']\n",
        "num_ratings_rating_less_than_5 = rating_book_users[rating_book_users['rating'] < 5]['number_of_ratings']\n",
        "\n",
        "# Perform a one-tailed t-test (greater)\n",
        "t_stat, p_value = stats.ttest_ind(num_ratings_rating_5, num_ratings_rating_less_than_5, alternative='greater')\n",
        "\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Print results\n",
        "print(\"t-statistic:\", t_stat)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The average number of ratings for books with a rating of 5\\\n",
        "          \\nis higher than the average number of ratings for books with a rating less than 5.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The average number of ratings for books with a rating of 5\\\n",
        "            \\nis equal to the average number of ratings for books with a rating less than 5.\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test are performed to find P-value"
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** T-test is commonly used to compare the means of two samples or groups to assess whether the observed difference is statistically significant or if it could have occurred by chance."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Making copy of original dataframe\n",
        "df=final_rating.copy()"
      ],
      "metadata": {
        "id": "JG6G_ZefAELm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "fgBvpgYczSTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "YgqVYNRhe75R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "sPq-Gh3efNN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.isnull().sum()"
      ],
      "metadata": {
        "id": "qEa8d-rYgeyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mode_publisher = book_data['publisher'].mode()[0]\n",
        "mode_author = book_data['author'].mode()[0]\n",
        "\n",
        "# Fill missing values in 'publisher' and 'author' columns with their respective modes\n",
        "book_data['publisher'].fillna(mode_publisher, inplace=True)\n",
        "book_data['author'].fillna(mode_author, inplace=True)"
      ],
      "metadata": {
        "id": "LShjnKvmgmYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "book_data.isnull().sum()"
      ],
      "metadata": {
        "id": "lAJcFHwghiAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** There is no missing value in the dataset. Hence no need to impute any missing value."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "sns.boxplot(df)"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** There is no outlier in the dataset."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "avg_rating=df.groupby('ISBN').mean()['rating'].reset_index()\n",
        "avg_rating.rename(columns= {'rating':'avg_ratings'}, inplace=True)\n",
        "avg_rating.head()"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Merging avg_rating dataset with original df dataset on 'ISBN'"
      ],
      "metadata": {
        "id": "AFkkxKKJQ3dA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_rating_df=df.merge(avg_rating,on='ISBN')\n",
        "avg_rating_df.head()"
      ],
      "metadata": {
        "id": "2qrJulY6QeXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=book_data.copy()"
      ],
      "metadata": {
        "id": "fg0dSclgV5UH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "fY0v4SHl6vKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "def string_lower(word):\n",
        "  return word.lower()\n",
        "df['title']=df['title'].apply(string_lower)\n",
        "# df['author']=df['author'].apply(string_lower)\n",
        "# df['publisher']=df['publisher'].apply(string_lower)"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "gS1012jx_ZR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "[punc for punc in string.punctuation]"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_punc(text):\n",
        "  nopunc =[char for char in text if char not in string.punctuation]\n",
        "  nopunc=''.join(nopunc)\n",
        "  return nopunc\n",
        "df['title']=df['title'].apply(remove_punc)\n",
        "# df['author']=df['author'].apply(remove_punc)\n",
        "# df['publisher']=df['publisher'].apply(remove_punc)"
      ],
      "metadata": {
        "id": "ZjN0Xzp4AVO3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "\n",
        "# Function to remove digits from text & sentence\n",
        "def remove_digits(text):\n",
        "  return ''.join([char for char in text if not char.isdigit()])\n",
        "\n",
        "# Apply the remove_digits function to the 'title' column\n",
        "df['title']=df['title'].apply(remove_digits)"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopword\n",
        "\n",
        "def remove_stopwords(sentence, language='english'):\n",
        "  # Get the list of stopwords for the specified language\n",
        "  stop_words = set(stopwords.words(language))\n",
        "  words = sentence.split()\n",
        "\n",
        "  # Remove stopwords from the list of words\n",
        "  filtered_words = [word for word in words if word not in stop_words]\n",
        "\n",
        "  # Join the filtered words to form a sentence without stopwords\n",
        "  filtered_sentence = ' '.join(filtered_words)\n",
        "  return filtered_sentence"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['title']=df['title'].apply(remove_stopwords)"
      ],
      "metadata": {
        "id": "5XvjdKopIJx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "df['title']=df['title'].replace(\" \",\"\")"
      ],
      "metadata": {
        "id": "YBOa7XenZxcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text\n",
        "# Create a new columns & Concatenate all the columns into it\n",
        "df.head()"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the 'tags' column using nltk\n",
        "df['title'] = df['title'].apply(word_tokenize)\n",
        "\n",
        "# Display the result\n",
        "df"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new dataframe\n",
        "book_data_new=df[['ISBN','title']]\n",
        "book_data_new"
      ],
      "metadata": {
        "id": "f0MVqSGhq4Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n",
        "\n",
        "# Create lemmatizer objects\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "\n",
        "# Define a function to lemmatize and join tokens\n",
        "def lemmatize_and_join(tokens):\n",
        "  # Lemmatize each token and join them back into a single string\n",
        "  lemmatized_text = \" \".join([lemmatizer.lemmatize(token) for token in tokens])\n",
        "\n",
        "  return lemmatized_text\n",
        "\n",
        "book_data_new['title']=book_data_new['title'].apply(lemmatize_and_join)\n",
        "book_data_new.head()"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Lemmatiztaion technique is used for text normalization because Lemmatization produces more linguistically correct and readable words compared to stemming."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "stopwords_list = stopwords.words('french') + stopwords.words('portuguese') + stopwords.words('spanish') + stopwords.words('german')+ stopwords.words('finnish')+ stopwords.words('swedish')\n",
        "\n",
        "#Trains a model whose vectors size is 5000, composed by the main unigrams and bigrams found in the corpus, ignoring stopwords\n",
        "vectorizer = TfidfVectorizer(analyzer='word',\n",
        "                     ngram_range=(1, 2),\n",
        "                     min_df=0.04,\n",
        "                     max_df=0.7,\n",
        "                     max_features=5000,\n",
        "                     stop_words=stopwords_list)\n",
        "tfidf_matrix = vectorizer.fit_transform(book_data_new['title'])\n",
        "tfidf_feature_names = vectorizer.get_feature_names_out()\n",
        "tfidf_matrix"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "r-NW_DIwzIbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_matrix.shape"
      ],
      "metadata": {
        "id": "pMnNqUN-29KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "qYsx-34y9Mpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(avg_rating_df,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training set lengths: {len(train_data)}')\n",
        "print(f'Testing set lengths: {len(test_data)}')\n",
        "print(f'Test set is {(len(test_data)/(len(train_data)+len(test_data))*100):.0f}% of the full dataset.')"
      ],
      "metadata": {
        "id": "6uRNtEF-5Cm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:** Splitting ratio is set to 20 % because it is a usual practice keep 80 % of data for training purpose & 20% data for testing purpose."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Indexing by user_id to speed up the searches during evaluation\n",
        "rating_full_df = avg_rating_df.set_index('user_id')\n",
        "rating_train_df =train_data.set_index('user_id')\n",
        "rating_test_df = test_data.set_index('user_id')"
      ],
      "metadata": {
        "id": "0Nvc3qTzV3zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.head()"
      ],
      "metadata": {
        "id": "2CBNyZCJ5-xK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1-Collaborative Filtering Method"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a sparse pivot table with ISBN in rows and user_id in columns\n",
        "users_items_pivot_matrix_df = train_data.pivot_table(columns='ISBN', index='user_id', values=\"rating\")"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix_df.shape"
      ],
      "metadata": {
        "id": "M3qDN2gcpioj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix_df.head()"
      ],
      "metadata": {
        "id": "JSykv0jjpx6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix_df.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "L1YYwlW_pxv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix_df.head()"
      ],
      "metadata": {
        "id": "wzyaLJIpqVDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix=users_items_pivot_matrix_df.values\n",
        "users_items_pivot_matrix[:10]"
      ],
      "metadata": {
        "id": "L2ss_MnyVKVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_id = list(users_items_pivot_matrix_df.index)\n",
        "user_id[:10]"
      ],
      "metadata": {
        "id": "TVgYqoBXVN4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of factors to factor the user-item matrix.\n",
        "NUMBER_OF_FACTORS_MF = 15\n",
        "\n",
        "#Performs matrix factorization of the original user item matrix\n",
        "U, sigma, Vt = svds(users_items_pivot_matrix, k = NUMBER_OF_FACTORS_MF)"
      ],
      "metadata": {
        "id": "RiOIArE7VpTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_pivot_matrix.shape"
      ],
      "metadata": {
        "id": "QWe8zFTFVtJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "U.shape"
      ],
      "metadata": {
        "id": "yMCSuRr4Vw6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sigma = np.diag(sigma)\n",
        "sigma.shape"
      ],
      "metadata": {
        "id": "7wU5YNelVz0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Vt.shape"
      ],
      "metadata": {
        "id": "mHdZTCGiV5aT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_user_predicted_ratings = np.dot(np.dot(U, sigma), Vt)\n",
        "all_user_predicted_ratings"
      ],
      "metadata": {
        "id": "YtjuQZrjV8iG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_user_predicted_ratings.shape"
      ],
      "metadata": {
        "id": "0dQRFCJ6WFSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting the reconstructed matrix back to a Pandas dataframe\n",
        "cf_preds_df = pd.DataFrame(all_user_predicted_ratings, columns = users_items_pivot_matrix_df.columns, index=user_id).transpose()\n",
        "cf_preds_df.head()"
      ],
      "metadata": {
        "id": "QEM_shH6qcTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cf_preds_df.columns)"
      ],
      "metadata": {
        "id": "bXHhLEtYWXMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CFRecommender:\n",
        "\n",
        "    MODEL_NAME = 'Collaborative Filtering'\n",
        "\n",
        "    def __init__(self, cf_predictions_df, items_df=None):\n",
        "        self.cf_predictions_df = cf_predictions_df\n",
        "        self.items_df = items_df\n",
        "\n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        # Get and sort the user's predictions\n",
        "        sorted_user_predictions = self.cf_predictions_df[user_id].sort_values(ascending=False).reset_index().rename(columns={user_id: 'recStrength'})\n",
        "\n",
        "        # Recommend the highest predicted rating content that the user hasn't seen yet.\n",
        "        recommendations_df = sorted_user_predictions[~sorted_user_predictions['ISBN'].isin(items_to_ignore)].sort_values('recStrength', ascending = False).head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left',\n",
        "                                                          left_on = 'ISBN',\n",
        "                                                          right_on = 'ISBN')[['recStrength', 'ISBN','title']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "\n",
        "cf_recommender_model = CFRecommender(cf_preds_df,book_data_new)"
      ],
      "metadata": {
        "id": "xu9Mu6N7Wbe2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_items_interacted_collaborative(user_id, ratings_data):\n",
        "    interacted_items = ratings_data.loc[user_id]['ISBN']\n",
        "    return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
      ],
      "metadata": {
        "id": "fXE-M_PRXMVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Top-N accuracy metric choosen was Recall@N which evaluates whether the interacted item is among the top N items (hit) in the ranked list of 101 recommendations for a user."
      ],
      "metadata": {
        "id": "GVRa5Z-6XIRq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Top-N accuracy metrics consts\n",
        "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
        "\n",
        "class ModelEvaluator_collaborative:\n",
        "\n",
        "    # Function for getting the set of items which a user has not interacted with\n",
        "    def get_not_interacted_items_sample(self, user_id, sample_size, seed=42):\n",
        "        interacted_items = get_items_interacted_collaborative(user_id, rating_full_df)\n",
        "        all_items = set(book_data_new['ISBN'])\n",
        "        non_interacted_items = all_items - interacted_items\n",
        "\n",
        "        random.seed(seed)\n",
        "        non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "        return set(non_interacted_items_sample)\n",
        "\n",
        "    # Function to verify whether a particular item_id was present in the set of top N recommended items\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
        "            try:\n",
        "                index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "            except:\n",
        "                index = -1\n",
        "            hit = int(index in range(0, topn))\n",
        "            return hit, index\n",
        "\n",
        "    # Function to evaluate the performance of model for each user\n",
        "    def evaluate_model_for_user(self, model, user_id):\n",
        "      try:\n",
        "\n",
        "        # Getting the items in test set\n",
        "        interacted_values_testset = rating_test_df.loc[user_id]\n",
        "\n",
        "        if type(interacted_values_testset['ISBN']) == pd.Series:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "        else:\n",
        "            person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
        "\n",
        "        # Getting a ranked recommendation list from the model for a given user\n",
        "        person_recs_df = model.recommend_items(user_id, items_to_ignore=get_items_interacted_collaborative(user_id, rating_train_df),topn=10000000000)\n",
        "\n",
        "        hits_at_5_count = 0\n",
        "        hits_at_10_count = 0\n",
        "\n",
        "        # For each item the user has interacted in test set\n",
        "        for item_id in person_interacted_items_testset:\n",
        "\n",
        "            # Getting a random sample of 100 items the user has not interacted with\n",
        "            non_interacted_items_sample = self.get_not_interacted_items_sample(user_id, sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS)\n",
        "\n",
        "            # Combining the current interacted item with the 100 random items\n",
        "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
        "\n",
        "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
        "            valid_recs_df = person_recs_df[person_recs_df['ISBN'].isin(items_to_filter_recs)]\n",
        "            valid_recs = valid_recs_df['ISBN'].values\n",
        "\n",
        "            # Verifying if the current interacted item is among the Top-N recommended items\n",
        "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
        "            hits_at_5_count += hit_at_5\n",
        "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
        "            hits_at_10_count += hit_at_10\n",
        "\n",
        "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items\n",
        "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
        "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
        "\n",
        "        user_metrics = {'hits@5_count':hits_at_5_count,\n",
        "                          'hits@10_count':hits_at_10_count,\n",
        "                          'interacted_count': interacted_items_count_testset,\n",
        "                          'recall@5': recall_at_5,\n",
        "                          'recall@10': recall_at_10}\n",
        "        return user_metrics\n",
        "      except KeyError:\n",
        "        # Handle the KeyError gracefully, e.g., by returning default metrics or logging the error\n",
        "        print(f\"User with user_id {user_id} not found in the test set.\")\n",
        "        return {'hits@5_count': 0, 'hits@10_count': 0, 'interacted_count': 0, 'recall@5': 0, 'recall@10': 0}\n",
        "\n",
        "\n",
        "    # Function to evaluate the performance of model at overall level\n",
        "    def evaluate_model(self, model):\n",
        "\n",
        "        people_metrics = []\n",
        "\n",
        "        for idx, user_id in enumerate(list(rating_test_df.index.unique().values)):\n",
        "            person_metrics = self.evaluate_model_for_user(model, user_id)\n",
        "            person_metrics['_user_id'] = user_id\n",
        "            people_metrics.append(person_metrics)\n",
        "\n",
        "        print('{0} users processed' .format(idx))\n",
        "\n",
        "        detailed_results_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
        "\n",
        "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "\n",
        "        global_metrics = {'modelName': model.get_model_name(),\n",
        "                          'recall@5': global_recall_at_5,\n",
        "                          'recall@10': global_recall_at_10}\n",
        "        return global_metrics, detailed_results_df\n",
        "\n",
        "model_evaluator = ModelEvaluator_collaborative()"
      ],
      "metadata": {
        "id": "8_hMVrr5XTkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
        "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cf_recommender_model)\n",
        "\n",
        "# Move the user_id column to the first position\n",
        "user_id_column = cf_detailed_results_df['_user_id']  # Extract the user_id column\n",
        "cf_detailed_results_df = cf_detailed_results_df.drop(columns=['_user_id'])\n",
        "cf_detailed_results_df.insert(0, '_user_id', user_id_column)\n",
        "\n",
        "print('\\nGlobal metrics:\\n{}'.format(cf_global_metrics))\n",
        "cf_detailed_results_df.head(10)"
      ],
      "metadata": {
        "id": "gdcO5MtsXaxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Collaborative filtering is a popular approach in recommendation systems that leverages the collective preferences and behaviors of users to make personalized recommendations. It's based on the idea that users who have interacted with items in similar ways in the past are likely to have similar preferences in the future.\n",
        "\n",
        "The Collaborative Filtering model achieved a recall of 0.9576 for both recall@5 and recall@10. This means that, on average, the model successfully recommended nearly 96% of the relevant items within the top 5 and top 10 recommendations for all users."
      ],
      "metadata": {
        "id": "YA2PREkwFqs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 Content Based Filtering"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain vector embeddings of each word in our corpus using TF-IDF Vectorizer technique."
      ],
      "metadata": {
        "id": "XOSiZBf1WH_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_list"
      ],
      "metadata": {
        "id": "RbBdh1zOVcc6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_feature_names"
      ],
      "metadata": {
        "id": "PwCsaEI_VcR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To model the user profile, we take all the item profiles the user has interacted and average them. The average is weighted by the interaction strength. In other words, the articles the user has interacted the most (eg. liked or commented) will have a higher strength in the final user profile."
      ],
      "metadata": {
        "id": "MikoRXvLm96n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "item_ids = book_data_new['ISBN'].tolist()\n",
        "\n",
        "def get_item_profile(item_id):\n",
        "  try:\n",
        "    idx = item_ids.index(item_id)\n",
        "    item_profile = tfidf_matrix[idx:idx+1]\n",
        "    return item_profile\n",
        "\n",
        "  except ValueError:\n",
        "    # Handle the case where the item_id is not found\n",
        "    print(f\"Item with ISBN '{item_id}' not found in the list.\")\n",
        "    return None\n",
        "\n",
        "def get_item_profiles(ids):\n",
        "  item_profiles_list = []\n",
        "\n",
        "  for x in ids:\n",
        "    item_profile = get_item_profile(x)\n",
        "\n",
        "    if item_profile is not None:\n",
        "      # Ensure item_profile is a 2-D matrix with the same number of columns as tfidf_matrix\n",
        "      if item_profile.shape[1] == tfidf_matrix.shape[1]:\n",
        "        item_profiles_list.append(item_profile)\n",
        "\n",
        "  if item_profiles_list:\n",
        "      item_profiles = np.vstack(item_profiles_list)\n",
        "      return item_profiles\n",
        "  else:\n",
        "      return None\n",
        "\n",
        "\n",
        "def build_users_profile(user_id, avg_indexed_df):\n",
        "  interactions_person_df = avg_indexed_df.loc[user_id]\n",
        "  user_item_profiles = get_item_profiles(interactions_person_df['ISBN'])\n",
        "  user_item_strengths = np.array(interactions_person_df['avg_ratings']).reshape(-1, 1)\n",
        "  return user_item_strengths\n",
        "\n",
        "\n",
        "def build_users_profiles():\n",
        "  avg_indexed_df = avg_rating_df[avg_rating_df['ISBN'].isin(book_data_new['ISBN'])].set_index('user_id')\n",
        "  user_profiles = {}\n",
        "  for user_id in avg_indexed_df.index.unique():\n",
        "      user_profiles[user_id] = build_users_profile(user_id, avg_indexed_df)\n",
        "  return user_profiles\n"
      ],
      "metadata": {
        "id": "Pf-QOoyw0BIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_profiles = build_users_profiles()\n",
        "len(user_profiles)"
      ],
      "metadata": {
        "id": "KyX7KY69ozus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_profiles"
      ],
      "metadata": {
        "id": "1NzBzkXshB8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at a particular user profile. It is a unit vector of 5000 length. The value in each position represents how relevant is a token (unigram or bigram) for the selected user"
      ],
      "metadata": {
        "id": "529Lpco1iQFa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_profile = user_profiles[155916]\n",
        "print(user_profile.shape)\n",
        "\n",
        "pd.DataFrame(sorted(zip(tfidf_feature_names,\n",
        "                        user_profiles[178950].flatten().tolist()), key=lambda x: -x[1])[:20],\n",
        "             columns=['token', 'relevance'])"
      ],
      "metadata": {
        "id": "CYZZpGoQiTo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Class for Content-Based Filtering"
      ],
      "metadata": {
        "id": "eUEnXpFoi24l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContentBasedRecommender:\n",
        "\n",
        "    MODEL_NAME = 'Content-Based'\n",
        "\n",
        "    def __init__(self, items_df=None):\n",
        "        self.item_ids = item_ids\n",
        "        self.items_df = items_df\n",
        "\n",
        "    def get_model_name(self):\n",
        "        return self.MODEL_NAME\n",
        "\n",
        "    def _get_similar_items_to_user_profile(self, user_id, topn=1000):\n",
        "\n",
        "        # Compute the cosine similarity between the user profile and all item profiles\n",
        "        cosine_similarities = cosine_similarity(user_profiles[user_id], tfidf_matrix)\n",
        "\n",
        "        # Get the top similar items\n",
        "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
        "\n",
        "        # Sort the similar items by similarity\n",
        "        similar_items = sorted([(item_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
        "        return similar_items\n",
        "\n",
        "    def recommend_items(self, user_id, items_to_ignore=[], topn=10, verbose=False):\n",
        "        similar_items = self._get_similar_items_to_user_profile(user_id)\n",
        "\n",
        "        #Ignores items the user has already interacted\n",
        "        similar_items_filtered = list(filter(lambda x: x[0] not in items_to_ignore, similar_items))\n",
        "\n",
        "        recommendations_df = pd.DataFrame(similar_items_filtered, columns=['ISBN', 'recStrength']).head(topn)\n",
        "\n",
        "        if verbose:\n",
        "            if self.items_df is None:\n",
        "                raise Exception('\"items_df\" is required in verbose mode')\n",
        "\n",
        "            recommendations_df = recommendations_df.merge(self.items_df, how = 'left',\n",
        "                                                          left_on = 'ISBN',\n",
        "                                                          right_on = 'ISBN')[['recStrength', 'ISBN','title']]\n",
        "\n",
        "\n",
        "        return recommendations_df\n",
        "\n",
        "content_based_recommender_model = ContentBasedRecommender(book_data_new)"
      ],
      "metadata": {
        "id": "Zpr32V49jCoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "hSL-8qRmjvUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_items_interacted_content(user_id, ratings_data):\n",
        "  interacted_items = ratings_data.loc[user_id]['ISBN']\n",
        "  return set(interacted_items if type(interacted_items) == pd.Series else [interacted_items])"
      ],
      "metadata": {
        "id": "zoPCqlW5kCO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Top-N accuracy metrics consts\n",
        "EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS = 100\n",
        "\n",
        "class ModelEvaluator_content:\n",
        "\n",
        "    # Function for getting the set of items which a user has not interacted with\n",
        "    def get_not_interacted_items_sample(self, user_id, sample_size, seed=42):\n",
        "      interacted_items = get_items_interacted_content(user_id, rating_full_df)\n",
        "      all_items = set(book_data_new['ISBN'])\n",
        "      non_interacted_items = all_items - interacted_items\n",
        "\n",
        "      random.seed(seed)\n",
        "      non_interacted_items_sample = random.sample(non_interacted_items, sample_size)\n",
        "      return set(non_interacted_items_sample)\n",
        "\n",
        "    # Function to verify whether a particular item_id was present in the set of top N recommended items\n",
        "    def _verify_hit_top_n(self, item_id, recommended_items, topn):\n",
        "      try:\n",
        "        index = next(i for i, c in enumerate(recommended_items) if c == item_id)\n",
        "      except:\n",
        "        index = -1\n",
        "      hit = int(index in range(0, topn))\n",
        "      return hit, index\n",
        "\n",
        "\n",
        "    # Function to evaluate the performance of model for each user\n",
        "    def evaluate_model_for_user(self, model, user_id):\n",
        "      try:\n",
        "\n",
        "        # Getting the items in test set\n",
        "        interacted_values_testset = rating_test_df.loc[user_id]\n",
        "\n",
        "        if type(interacted_values_testset['ISBN']) == pd.Series:\n",
        "          person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "        else:\n",
        "          person_interacted_items_testset = set(interacted_values_testset['ISBN'])\n",
        "\n",
        "        interacted_items_count_testset = len(person_interacted_items_testset)\n",
        "\n",
        "        # Getting a ranked recommendation list from the model for a given user\n",
        "        person_recs_df = model.recommend_items(user_id, items_to_ignore=get_items_interacted_content(user_id, rating_train_df),topn=10000000000)\n",
        "\n",
        "        hits_at_5_count = 0\n",
        "        hits_at_10_count = 0\n",
        "\n",
        "        # For each item the user has interacted in test set\n",
        "        for item_id in person_interacted_items_testset:\n",
        "\n",
        "            # Getting a random sample of 100 items the user has not interacted with\n",
        "            non_interacted_items_sample = self.get_not_interacted_items_sample(user_id, sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_ITEMS)\n",
        "\n",
        "            # Combining the current interacted item with the 100 random items\n",
        "            items_to_filter_recs = non_interacted_items_sample.union(set([item_id]))\n",
        "\n",
        "            # Filtering only recommendations that are either the interacted item or from a random sample of 100 non-interacted items\n",
        "            valid_recs_df = person_recs_df[person_recs_df['ISBN'].isin(items_to_filter_recs)]\n",
        "            valid_recs = valid_recs_df['ISBN'].values\n",
        "\n",
        "            # Verifying if the current interacted item is among the Top-N recommended items\n",
        "            hit_at_5, index_at_5 = self._verify_hit_top_n(item_id, valid_recs, 5)\n",
        "            hits_at_5_count += hit_at_5\n",
        "            hit_at_10, index_at_10 = self._verify_hit_top_n(item_id, valid_recs, 10)\n",
        "            hits_at_10_count += hit_at_10\n",
        "\n",
        "        # Recall is the rate of the interacted items that are ranked among the Top-N recommended items\n",
        "        recall_at_5 = hits_at_5_count / float(interacted_items_count_testset)\n",
        "        recall_at_10 = hits_at_10_count / float(interacted_items_count_testset)\n",
        "\n",
        "        user_metrics = {'hits@5_count':hits_at_5_count,\n",
        "                          'hits@10_count':hits_at_10_count,\n",
        "                          'interacted_count': interacted_items_count_testset,\n",
        "                          'recall@5': recall_at_5,\n",
        "                          'recall@10': recall_at_10}\n",
        "        return user_metrics\n",
        "      except KeyError:\n",
        "        # Handle the KeyError gracefully, e.g., by returning default metrics or logging the error\n",
        "        print(f\"User with user_id {user_id} not found in the test set.\")\n",
        "        return {'hits@5_count': 0, 'hits@10_count': 0, 'interacted_count': 0, 'recall@5': 0, 'recall@10': 0}\n",
        "\n",
        "\n",
        "    # Function to evaluate the performance of model at overall level\n",
        "    def evaluate_model(self, model):\n",
        "\n",
        "        people_metrics = []\n",
        "\n",
        "        for idx, user_id in enumerate(list(rating_test_df.index.unique().values)):\n",
        "            person_metrics = self.evaluate_model_for_user(model,user_id)\n",
        "            person_metrics['_person_id'] = user_id\n",
        "            people_metrics.append(person_metrics)\n",
        "\n",
        "        print('{0} users processed' .format(idx))\n",
        "\n",
        "        detailed_results_df = pd.DataFrame(people_metrics).sort_values('interacted_count', ascending=False)\n",
        "\n",
        "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['interacted_count'].sum())\n",
        "\n",
        "        global_metrics = {'modelName': model.get_model_name(),\n",
        "                          'recall@5': global_recall_at_5,\n",
        "                          'recall@10': global_recall_at_10}\n",
        "        return global_metrics, detailed_results_df\n",
        "\n",
        "model_evaluator = ModelEvaluator_content()"
      ],
      "metadata": {
        "id": "oj3uPXQoj0M7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Evaluating Content-Based Filtering model...')\n",
        "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(content_based_recommender_model)\n",
        "\n",
        "# Move the person_id column to the first position\n",
        "user_id_column = cb_detailed_results_df['_person_id']\n",
        "cb_detailed_results_df = cb_detailed_results_df.drop(columns=['_person_id'])\n",
        "cb_detailed_results_df.insert(0, '_person_id', user_id_column)\n",
        "\n",
        "print('\\nGlobal metrics:\\n{}' .format(cb_global_metrics))\n",
        "cb_detailed_results_df.head(10)"
      ],
      "metadata": {
        "id": "Rv9MUXgmlb91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Content-based filtering is one of the fundamental approaches in recommendation systems that leverages information about the attributes or features of items and users to make personalized recommendations. It recommends items that are similar in content to those a user has shown interest in. This approach is particularly useful when you have detailed information about the characteristics of items and user preferences.\n",
        "\n",
        " The Content-Based model achieved a very low recall of approximately 0.0015 for both recall@5 and recall@10. This means that, on average, the model successfully recommended a very small percentage of relevant items within the top 5 and top 10 recommendations for all users."
      ],
      "metadata": {
        "id": "15vsFWCIjvG0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall@5 and Recall@10:\n",
        "\n",
        "* **Indication:** These metrics measure the percentage of relevant items that were successfully recommended within the top 5 and top 10 recommendations, respectively. A low recall indicates that the model is not effectively capturing and recommending relevant items.\n",
        "\n",
        "* **Business Impact:** Low recall can lead to several negative business impacts. It means that users are not seeing a significant portion of items that they might find interesting or relevant. This can result in reduced user engagement, satisfaction, and conversion rates. Users may not discover new products or content, limiting their interaction with the platform. Ultimately, this can lead to missed revenue opportunities and reduced user retention.\n",
        "\n",
        "\n",
        "Hits@5 and Hits@10:\n",
        "\n",
        "* **Indication:** These metrics count the number of hits, i.e., the number of relevant items that were recommended within the top 5 and top 10 recommendations. A low number of hits suggests that the model is not effectively recommending relevant items.\n",
        "* **Business Impact:** Low hits reflect missed opportunities for the business. Users may not find items they want to purchase, view, or engage with, leading to lost sales and revenue. Users may also become frustrated if they do not see items of interest, potentially leading to churn or reduced user satisfaction.\n",
        "\n",
        "\n",
        "**Interacted_Count:**\n",
        "\n",
        "* **Indication:** This metric represents the number of interactions (engagements) users have had with items. It provides context on the user's activity on the platform.\n",
        "* **Business Impact:** Understanding user interaction is important for personalization and recommendation. It helps in tailoring recommendations to user preferences and behavior. However, this metric doesn't directly indicate the model's performance."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 Model Based Recommendation"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.head()"
      ],
      "metadata": {
        "id": "2OjpF00x23rp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rating_book_users.columns"
      ],
      "metadata": {
        "id": "Cjj3hm46giBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "train_data_model, test_data_model = train_test_split(rating_book_users, test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "7RZ7jYD73P4-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training set lengths: {len(train_data_model)}')\n",
        "print(f'Testing set lengths: {len(test_data_model)}')\n",
        "print(f'Test set is {(len(test_data_model)/(len(train_data_model)+len(test_data_model))*100):.0f}% of the full dataset.')"
      ],
      "metadata": {
        "id": "ySbmugPP3e5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_matrix = train_data_model.pivot_table(columns='user_id', index='title', values=\"rating\")\n",
        "\n",
        "pivot_matrix"
      ],
      "metadata": {
        "id": "2MxPW2eT3s9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_matrix.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "85GzfJ354xoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pivot_matrix.head()"
      ],
      "metadata": {
        "id": "T2fmy27p49rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_items_model_based_pivot_matrix=pivot_matrix.values\n",
        "users_items_model_based_pivot_matrix[:10]"
      ],
      "metadata": {
        "id": "GH7ucPOr5D5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "title = list(pivot_matrix.index)\n",
        "title[:10]"
      ],
      "metadata": {
        "id": "JhcF5Y3g5WPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the pivot matrix into sparse matrix\n",
        "from scipy.sparse import csr_matrix\n",
        "book_sparse = csr_matrix(pivot_matrix)\n"
      ],
      "metadata": {
        "id": "582VfUoTB1He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "model = NearestNeighbors(n_neighbors=10, metric='cosine',algorithm='brute')\n",
        "\n",
        "# Fit the Algorithm\n",
        "model.fit(book_sparse)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def auto_recommend_random_books(test_data_model, num_books=5, num_recommendations=5):\n",
        "  recommended_books_for_each = []\n",
        "\n",
        "  try:\n",
        "    # Randomly select 5 books\n",
        "    random_book_indices = np.random.choice(len(pivot_matrix.index), num_books, replace=False)\n",
        "    random_book_names = [pivot_matrix.index[i] for i in random_book_indices]\n",
        "\n",
        "    for book_name in random_book_names:\n",
        "      # Check if the book_name exists in the index\n",
        "      if book_name not in pivot_matrix.index:\n",
        "        raise KeyError(f\"'{book_name}' not found in the index.\")\n",
        "\n",
        "      # Fetch index of book_name\n",
        "      index = np.where(pivot_matrix.index == book_name)[0][0]\n",
        "\n",
        "      # Find the nearest neighbors\n",
        "      distances, neighbor_indices = model.kneighbors(book_sparse[index].reshape(1, -1))\n",
        "\n",
        "      # Exclude the first neighbor, which is the book itself\n",
        "      similar_items = neighbor_indices[0][1:]\n",
        "      similar_distances = distances[0][1:]\n",
        "\n",
        "      # Get the recommended books and distances\n",
        "      recommended_books_with_distances = [(pivot_matrix.index[i], distance) for i, distance in zip(similar_items[:num_recommendations], similar_distances)]\n",
        "\n",
        "      recommended_books_for_each.append((book_name, recommended_books_with_distances))\n",
        "\n",
        "    return recommended_books_for_each\n",
        "\n",
        "  except KeyError as e:\n",
        "    print(e)\n",
        "    return []\n",
        "\n",
        "recommended_books_for_each = auto_recommend_random_books(test_data_model, num_books=5, num_recommendations=5)\n",
        "\n",
        "for book_name, recommended_books_with_distances in recommended_books_for_each:\n",
        "  if recommended_books_with_distances:\n",
        "    print(f\"Recommended books for '{book_name}':\")\n",
        "    for i, (recommended_book, distance) in enumerate(recommended_books_with_distances):\n",
        "      print(f\"{i + 1}. Book: {recommended_book}, Distance: {distance}\")\n",
        "    print()\n",
        "  else:\n",
        "    print(f\"No recommendations available for '{book_name}'.\")"
      ],
      "metadata": {
        "id": "J9mhuupURqnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " k-Nearest Neighbors (k-NN) model with cosine similarity as the distance metric is used to build the recommendatyion system. This model is utilized to provide book recommendations based on the similarity between books in a high-dimensional space defined by their content or features."
      ],
      "metadata": {
        "id": "mwTPnpslUwIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hit Rate is considered best for the current business scenario because The hit rate measures the percentage of users who received at least one relevant recommendation in the top-k recommendations.\n",
        "\n",
        "**Business Impact:** A high hit rate implies that a significant portion of users found something they liked among the recommendations. This can enhance user engagement and potentially lead to increased sales or user satisfaction."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ans:-** Collaborative Filtering model is performing well with a high recall of 95%! High recall in a recommendation system is often a positive sign, as it indicates that the system is effectively capturing a large portion of relevant items and providing them to users.\n",
        "\n",
        "Hence Collaborative Filtering based Recommendation System performs well with current dataset."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "import pickle\n",
        "\n",
        "with open('rating_book_users.pkl', 'wb') as file:\n",
        "    pickle.dump(rating_book_users, file)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "with open('rating_book_users.pkl', 'rb') as file:\n",
        "    loaded_model = pickle.load(file)"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In our quest to develop an effective book recommendation system, we explored and implemented three distinct approaches: Collaborative Filtering, Content-Based Filtering, and k-Nearest Neighbors (k-NN). After thorough experimentation and evaluation, we have reached a conclusion regarding the most suitable model for deployment.\n",
        "\n",
        "**Collaborative Filtering Shines:**\n",
        "\n",
        "Among the three models we explored, Collaborative Filtering demonstrated exceptional performance. It leveraged user behavior and preferences to generate book recommendations, and it stood out with an impressive recall rate of 95%. This high recall indicates that the Collaborative Filtering model effectively captures a vast portion of relevant books, ensuring that users are exposed to items that closely align with their interests and preferences. This aligns well with our goal of maximizing user satisfaction and engagement.\n",
        "\n",
        "Collaborative Filtering's strengths in user-centric recommendations, its ability to uncover latent patterns in user behavior, and its adaptability to various user interactions make it a standout choice. This model effectively balances precision and recall, ensuring that users receive both accurate and comprehensive recommendations. Its exceptional performance and user-centric approach make it the most promising candidate for deployment.\n",
        "\n",
        "**Choosing Collaborative Filtering for Deployment:**\n",
        "\n",
        "Given its outstanding performance and alignment with our objectives, we have selected Collaborative Filtering as our final model for deployment in the book recommendation system. This choice reflects our commitment to providing users with high-quality, personalized book recommendations that enhance their overall experience.\n",
        "\n",
        "With Collaborative Filtering as our final model, we are well-positioned to achieve our business goals, including increased user satisfaction, engagement, and potentially higher book sales. Collaborative Filtering's adaptability also allows us to continually refine and personalize recommendations as user preferences evolve over time.\n",
        "\n",
        "In summary, our journey to build a book recommendation system has led us to Collaborative Filtering as the most effective and promising model for deployment."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}